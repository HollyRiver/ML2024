{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Total imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## model\n",
    "import sklearn.linear_model\n",
    "import statsmodels.api as sm\n",
    "from pygam import LinearGAM, s, f\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "\n",
    "## cv\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "## evaluation\n",
    "from sklearn.metrics import RocCurveDisplay, confusion_matrix\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "## visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "## utilities\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "## 한글 폰트 표시\n",
    "plt.rcParams['font.family'] ='NanumGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "## 렌더링 설정\n",
    "pio.templates.default = 'plotly_white'\n",
    "pio.renderers.default = \"vscode\"\n",
    "\n",
    "## warnings 처리\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 데이터 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_price = pd.read_csv(\"kc_house_data.csv\")\n",
    "\n",
    "## 전처리\n",
    "df_preprocessed = housing_price.drop([\"id\", \"date\", \"price\"], axis = 1)\\\n",
    ".assign(date = pd.to_datetime(housing_price.date)).assign(price = housing_price.price)\n",
    "\n",
    "## scores recoding\n",
    "scoring_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 자료 분할**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_days_split(df_train : pd.DataFrame, df_test : pd.DataFrame) :\n",
    "    \"\"\"\n",
    "    train/test set에서 `date` 열을 월별과 일별로 따로 분석하기 위한 함수\n",
    "    \"\"\"\n",
    "    test_month = df_test.date.dt.month.astype(str)\n",
    "    test_days = df_test.date.map(lambda x : x - df_preprocessed.date.min()).dt.days\n",
    "    train_month = df_train.date.dt.month.astype(str)\n",
    "    train_days = df_train.date.map(lambda x : x - df_preprocessed.date.min()).dt.days\n",
    "    \n",
    "    return [train_month, train_days], [test_month, test_days]\n",
    "\n",
    "df_train, df_test = train_test_split(df_preprocessed, test_size = 0.3, shuffle = True, random_state = 14107)\n",
    "df_train = df_train.reset_index(drop = True)\n",
    "df_test = df_test.reset_index(drop = True)\n",
    "\n",
    "train_date, test_date = month_days_split(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualization & EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 예측변수 주택 판매 가격의 분포**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (12,5))\n",
    "\n",
    "axs[0].hist(df_train.price, bins = 100)\n",
    "axs[0].set_title(\"주택 가격 히스토그램\")\n",
    "axs[0].set_xlabel(\"price(100,000$)\")\n",
    "axs[0].set_ylabel(\"count\")\n",
    "axs[1].boxplot(df_train.price, flierprops={'marker': 'o', 'markersize': 1, 'markerfacecolor': 'fuchsia'})\n",
    "axs[1].text(1.1, 0, f\"min = {df_train.price.min():.0f}\", fontsize=10)\n",
    "axs[1].text(1.1, 375000, f\"med = {df_train.price.median():.0f}\", fontsize=10)\n",
    "axs[1].text(1.1, 7650000, f\"max = {df_train.price.max():.0f}\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 각 설명변수들과 예측변수 간 관계 파악**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 개별 설명변수(구매일자 제외)와 예측변수 간 산점도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 열 설명 딕셔너리 작성\n",
    "description_list = [\"ID\", \"주택 거래일\", \"주택 판매가격\", \"침실의 수\", \"화장실의 수\", \"주택 내부 생활공간 면적\",\n",
    "                    \"가용 토지공간 면적\", \"주택 층수\", \"물가뷰\", \"전망 평가지수\", \"주택상태 평가지수\", \"전반적 주택품질 평가지수\",\n",
    "                    \"지상 내부공간 면적\", \"지하 내부공간 면적\", \"주택 완공년도\", \"마지막 주택 보수년도\", \"지역 우편번호\",\n",
    "                    \"위도\", \"경도\", \"인접 15개 가구 내부 생활공간 면적\", \"인접 15개 가구 가용 토지공간 면적\"]\n",
    "\n",
    "data_dict = {v:d for v, d in zip(housing_price.columns, description_list)}\n",
    "col_list = df_train.columns\n",
    "\n",
    "## 산점도\n",
    "fig, axs = plt.subplots(5, 4, figsize = (12,12))\n",
    "\n",
    "for i in range(5) :\n",
    "    for j in range(4) :\n",
    "        if (i*4+j >= 18) :\n",
    "            break\n",
    "            \n",
    "        axs[i, j].scatter(df_train.iloc[:, i*4+j], df_train.price, s = 0.5, alpha = 0.3)\n",
    "        axs[i, j].set_title(data_dict[col_list[i*4+j]])\n",
    "\n",
    "        if col_list[i*4+j] in (\"long\", \"sqft_lot15\") :\n",
    "            axs[i, j].tick_params(axis='x', rotation=-30)\n",
    "\n",
    "axs[4, 2].remove()\n",
    "axs[4, 3].remove()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 구매 일자 관련 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 월별 주택 판매가격 상자 그림\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Box(\n",
    "        x = train_date[0].astype(int), y = df_train.price,\n",
    "        notched=True\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title=dict(text=\"월별 주택 판매 가격에 대한 상자 그림\", font=dict(size=30), x = 0.5, y = 0.95), height = 800)\n",
    "fig.update_xaxes(dtick=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 주택 판매일과 주택 가격 간 산점도\n",
    "plt.scatter(train_date[1], df_train.price, s = 0.5, alpha = 0.3)\n",
    "plt.title(\"일별 거래량과 가격 산점도\")\n",
    "plt.xlabel(\"Days(Starting from 2014-05-02)\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 실제 위치 별 주택 가격 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_train.loc[:, [\"lat\", \"long\", \"price\"]]\n",
    "\n",
    "with open('/root/ML2024/hw/기말 발표/graphics/King County.geojson', 'r') as f:\n",
    "    king_county_boundary = json.load(f)\n",
    "\n",
    "fig = px.density_mapbox(\n",
    "    data_frame = df_feature,\n",
    "    lat = 'lat',\n",
    "    lon = 'long',\n",
    "    radius = 9,  ## 줌 스케일과 무관하게 크기가 상대적으로 설정됨\n",
    "    center = {'lat' : 47.4421, 'lon' : -121.8089},\n",
    "    z = 'price',  ## 색상으로 표시할 변수\n",
    "    #---#\n",
    "    mapbox_style = 'carto-positron',\n",
    "    zoom = 8.9,\n",
    "    width = 1200,\n",
    "    height = 900\n",
    ")\n",
    "\n",
    "# King County 경계선 추가\n",
    "fig.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=king_county_boundary,\n",
    "        locations=[feature['id'] for feature in king_county_boundary['features']], # geojson ID와 매핑\n",
    "        z=[1] * len(king_county_boundary['features']), # 동일 값을 지정\n",
    "        colorscale=[[0, \"rgba(0,0,0,0)\"], [1, \"red\"]], # 투명도 + 빨간색 경계\n",
    "        showscale=False, # 컬러바 숨기기\n",
    "        marker_opacity=0.2, # 경계 영역 투명도 설정\n",
    "        marker_line_width=2 # 경계선 두께 설정\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show(config = {'scrollZoom' : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D. 변수 간 선형 상관계수 히트맵(절대값 스케일)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generating tidy data\n",
    "tidy_data = df_train.corr().stack().reset_index().rename({\"level_0\" : \"var1\", \"level_1\" : \"var2\", 0 : \"correlation\"}, axis = 1)\\\n",
    ".assign(abs_corr = lambda _df : _df.correlation.map(lambda x : abs(x)))\n",
    "tidy_data = pd.concat([tidy_data.loc[tidy_data.var1 == 'bedrooms'][::-1], tidy_data.iloc[20:, :]], axis = 0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = tidy_data.var1, y = tidy_data.var2, z = tidy_data.abs_corr,\n",
    "        text = tidy_data.correlation, texttemplate=\"%{text:.2f}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title=dict(text=\"20개 변수 간 상관계수\", font=dict(size=30), x = 0.5, y = 0.95), height = 800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>abs_corr</th>\n",
       "      <th>combine_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>sqft_living</td>\n",
       "      <td>0.756053</td>\n",
       "      <td>0.756053</td>\n",
       "      <td>{sqft_living, bathrooms}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>grade</td>\n",
       "      <td>0.764164</td>\n",
       "      <td>0.764164</td>\n",
       "      <td>{sqft_living, grade}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>sqft_above</td>\n",
       "      <td>0.878998</td>\n",
       "      <td>0.878998</td>\n",
       "      <td>{sqft_living, sqft_above}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>0.753548</td>\n",
       "      <td>0.753548</td>\n",
       "      <td>{sqft_living, sqft_living15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>price</td>\n",
       "      <td>0.701565</td>\n",
       "      <td>0.701565</td>\n",
       "      <td>{sqft_living, price}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>0.710831</td>\n",
       "      <td>0.710831</td>\n",
       "      <td>{sqft_lot15, sqft_lot}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>grade</td>\n",
       "      <td>sqft_above</td>\n",
       "      <td>0.755626</td>\n",
       "      <td>0.755626</td>\n",
       "      <td>{grade, sqft_above}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>grade</td>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>0.713762</td>\n",
       "      <td>0.713762</td>\n",
       "      <td>{sqft_living15, grade}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>0.728683</td>\n",
       "      <td>0.728683</td>\n",
       "      <td>{sqft_living15, sqft_above}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            var1           var2  correlation  abs_corr  \\\n",
       "22     bathrooms    sqft_living     0.756053  0.756053   \n",
       "48   sqft_living          grade     0.764164  0.764164   \n",
       "49   sqft_living     sqft_above     0.878998  0.878998   \n",
       "56   sqft_living  sqft_living15     0.753548  0.753548   \n",
       "59   sqft_living          price     0.701565  0.701565   \n",
       "77      sqft_lot     sqft_lot15     0.710831  0.710831   \n",
       "169        grade     sqft_above     0.755626  0.755626   \n",
       "176        grade  sqft_living15     0.713762  0.713762   \n",
       "196   sqft_above  sqft_living15     0.728683  0.728683   \n",
       "\n",
       "                      combine_set  \n",
       "22       {sqft_living, bathrooms}  \n",
       "48           {sqft_living, grade}  \n",
       "49      {sqft_living, sqft_above}  \n",
       "56   {sqft_living, sqft_living15}  \n",
       "59           {sqft_living, price}  \n",
       "77         {sqft_lot15, sqft_lot}  \n",
       "169           {grade, sqft_above}  \n",
       "176        {sqft_living15, grade}  \n",
       "196   {sqft_living15, sqft_above}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 상관계수의 절대값이 0.7 이상인 변수들\n",
    "tidy_data.loc[(tidy_data.abs_corr > 0.7) & (tidy_data.var1 != tidy_data.var2)]\\\n",
    ".assign(combine_set = lambda _df : (_df.var1 + \" \" + _df.var2).str.split().map(lambda x : set(x)))\\\n",
    ".loc[lambda _df : _df.combine_set.drop_duplicates().index].drop(\"combine_set\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. 다중선형회귀모형 적용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----일별 분석-----\n",
    "## 1. data : 일별 분석\n",
    "X = df_train.drop([\"date\", \"price\"], axis = 1).assign(days = train_date[1])\n",
    "y = df_train.price\n",
    "\n",
    "XX = df_test.drop([\"date\", \"price\"], axis = 1).assign(days = test_date[1])\n",
    "yy = df_test.price\n",
    "\n",
    "## 2. predictor\n",
    "predictr = sklearn.linear_model.LinearRegression()\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## 3. prediction\n",
    "yyhat = predictr.predict(XX)\n",
    "\n",
    "## 4. evaluation\n",
    "scoring_dict[\"Linear Regression with days\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")\n",
    "\n",
    "#-----월별 분석-----\n",
    "## 1. data\n",
    "X = pd.get_dummies(df_train.drop([\"date\", \"price\"], axis = 1).assign(month = train_date[0]), drop_first = True, dtype = int)\n",
    "y = df_train.price\n",
    "\n",
    "XX = pd.get_dummies(df_test.drop([\"date\", \"price\"], axis = 1).assign(month = test_date[0]), drop_first = True, dtype = int)\n",
    "yy = df_test.price\n",
    "\n",
    "\n",
    "## 2. predictor\n",
    "predictr = sklearn.linear_model.LinearRegression()\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## 3. prediction\n",
    "yyhat = predictr.predict(XX)\n",
    "\n",
    "## 4. evaluation\n",
    "scoring_dict[\"Linear Regression with month\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")\n",
    "\n",
    "## ANOVA table\n",
    "model = sm.OLS(y, pd.concat([pd.DataFrame({'intercept' : np.ones(X.shape[0])}), X], axis = 1))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. 벌점 함수 모형 적용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. Ridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 변수 스케일링 / 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw price RMSE = 196381.8609\n",
      "transformed price RMSE = 221208.7680\n",
      "raw price 1se rule RMSE = 200062.3972\n",
      "transformed price 1se rule RMSE = 240907.1497\n"
     ]
    }
   ],
   "source": [
    "##------범주형 반응변수는 전부 스케일링 하지 않음------\n",
    "\n",
    "## fitting scaler with train set\n",
    "numeric_features = list(set(df_train.columns) - set([\"price\", \"date\", \"waterfront\"])) ## date : 선형이므로 월별로 설정(더미변수 처리)\n",
    "scalr = StandardScaler()\n",
    "y_scalr = PowerTransformer()\n",
    "standarized_features = scalr.fit_transform(df_train.loc[:, numeric_features])\n",
    "\n",
    "## train data\n",
    "X_trans = np.concatenate([standarized_features, np.asarray(pd.get_dummies(train_date[0], drop_first = True, dtype = int).assign(waterfront = df_train.waterfront))], axis = 1) # features\n",
    "y_trans = np.asarray(y_scalr.fit_transform(pd.DataFrame(df_train.price))).reshape(-1) ## scaled target\n",
    "\n",
    "## test data\n",
    "XX_trans = np.concatenate([scalr.transform(df_test.loc[:, numeric_features]), np.asarray(pd.get_dummies(test_date[0], drop_first = True, dtype = int).assign(waterfront = df_test.waterfront))], axis = 1)\n",
    "yy_trans = np.asarray(y_scalr.transform(pd.DataFrame(df_test.price))).reshape(-1)\n",
    "\n",
    "\n",
    "## fitting and cross validation(10-fold)\n",
    "lambdas = 10**np.linspace(1, -5, 100) ## setting grid for plotting\n",
    "kfold = KFold(10, random_state = 14107, shuffle = True)\n",
    "ridgeCV = sklearn.linear_model.ElasticNetCV(alphas = lambdas, l1_ratio = 0, cv = kfold)\n",
    "ridgeCV.fit(X_trans, y)\n",
    "\n",
    "## fitting and cross validation(10-fold)\n",
    "lambdas = 10**np.linspace(1, -5, 100) ## setting grid for plotting\n",
    "kfold = KFold(10, random_state = 14107, shuffle = True)\n",
    "ridgeCV_trans = sklearn.linear_model.ElasticNetCV(alphas = lambdas, l1_ratio = 0, cv = kfold)\n",
    "ridgeCV_trans.fit(X_trans, y_trans)\n",
    "\n",
    "##----------prediction----------\n",
    "\n",
    "## CV optimized predictor : raw price\n",
    "predictr_optim = sklearn.linear_model.ElasticNet(alpha = ridgeCV.alpha_, l1_ratio = 0)\n",
    "predictr_optim.fit(X_trans, y)\n",
    "scoring_dict[\"Ridge Regression\"] = np.mean((yy - predictr_optim.predict(XX_trans))**2)**0.5\n",
    "print(f\"raw price RMSE = {np.mean((yy - predictr_optim.predict(XX_trans))**2)**0.5:.4f}\")\n",
    "\n",
    "## CV optimized predictor : transformed price\n",
    "predictr_optim_trans = sklearn.linear_model.ElasticNet(alpha = ridgeCV_trans.alpha_, l1_ratio = 0)\n",
    "predictr_optim_trans.fit(X_trans, y_trans)\n",
    "scoring_dict[\"Ridge Regression with transformed price\"] = np.mean((yy - y_scalr.inverse_transform(predictr_optim.predict(XX_trans).reshape(-1,1)).reshape(-1))**2)**0.5\n",
    "print(f\"transformed price RMSE = {np.mean((yy - y_scalr.inverse_transform(predictr_optim.predict(XX_trans).reshape(-1,1)).reshape(-1))**2)**0.5:.4f}\")\n",
    "\n",
    "## 1-se-rule predictor : raw price\n",
    "mse_list = ridgeCV.mse_path_.mean(1)\n",
    "indx = np.where(mse_list == np.min(mse_list))\n",
    "min_mse = mse_list[indx]\n",
    "min_std = ridgeCV.mse_path_.std(1)[indx]\n",
    "simple_indx = np.min(np.where(mse_list <= min_mse + min_std / np.sqrt(10)))\n",
    "predictr_1se = sklearn.linear_model.ElasticNet(alpha = ridgeCV.alphas_[simple_indx], l1_ratio = 0)\n",
    "predictr_1se.fit(X_trans, y)\n",
    "yyhat = predictr_1se.predict(XX_trans)\n",
    "scoring_dict[\"Ridge Regression with 1-se rule\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"raw price 1se rule RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")\n",
    "\n",
    "## 1-se-rule predictor : transformed price\n",
    "mse_list_trans = ridgeCV_trans.mse_path_.mean(1)\n",
    "indx_trans = np.where(mse_list_trans == np.min(mse_list_trans))\n",
    "min_mse_trans = mse_list_trans[indx_trans]\n",
    "min_std_trans = ridgeCV_trans.mse_path_.std(1)[indx]\n",
    "simple_indx_trans = np.min(np.where(mse_list_trans <= min_mse_trans + min_std_trans / np.sqrt(10)))\n",
    "predictr_1se = sklearn.linear_model.ElasticNet(alpha = ridgeCV_trans.alphas_[simple_indx_trans], l1_ratio = 0)\n",
    "predictr_1se.fit(X_trans, y_trans)\n",
    "yyhat = y_scalr.inverse_transform(predictr_1se.predict(XX_trans).reshape(-1,1)).reshape(-1)\n",
    "scoring_dict[\"Ridge Regression with transformed price & 1-se rule\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"transformed price 1se rule RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 시각화 및 $\\lambda$값 식별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n",
    "ridgeCV_fig, axs = plt.subplots(1, 2, figsize=(16,8))\n",
    "axs[0].errorbar(-np.log(ridgeCV.alphas_), ridgeCV.mse_path_.mean(1),\n",
    "            yerr=ridgeCV.mse_path_.std(1) / np.sqrt(10))\n",
    "axs[0].axvline(-np.log(ridgeCV.alpha_), c='k', ls='--')\n",
    "axs[0].axhline(min_mse + min_std / np.sqrt(10), c = 'k', ls = '--')\n",
    "axs[0].set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "axs[0].set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "axs[0].scatter(-np.log(ridgeCV.alphas_[simple_indx]), mse_list[simple_indx],\n",
    "           color = \"red\", s = 15, label = \"1-se rule selection\", zorder = 5)\n",
    "axs[0].set_title(\"반응변수 변환이 없는 경우 CV MSE와 그 표준오차\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].errorbar(-np.log(ridgeCV_trans.alphas_), ridgeCV_trans.mse_path_.mean(1),\n",
    "            yerr=ridgeCV_trans.mse_path_.std(1) / np.sqrt(10))\n",
    "axs[1].axvline(-np.log(ridgeCV_trans.alpha_), c='k', ls='--')\n",
    "axs[1].axhline(min_mse_trans + min_std_trans / np.sqrt(10), c = 'k', ls = '--')\n",
    "axs[1].set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "axs[1].set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "axs[1].scatter(-np.log(ridgeCV_trans.alphas_[simple_indx_trans]), mse_list_trans[simple_indx_trans],\n",
    "           color = \"red\", s = 15, label = \"1-se rule selection\", zorder = 5)\n",
    "axs[1].set_title(\"반응응변수를 파워변환 한 경우 CV MSE와 그 표준오차\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## showing parameter\n",
    "print(f'선택된 lambda(raw) = {ridgeCV.alpha_ : .5f}, {ridgeCV.alphas_[simple_indx] : .5f}')\n",
    "print(f\"선택된 lambda(powertransform) = {ridgeCV_trans.alpha_ : .5f}, {ridgeCV_trans.alphas_[simple_indx_trans] : .5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 범주형 반응변수까지 전부 스케일링하는 경우(성능 진짜 조금 감소)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw price RMSE = 196385.8038\n",
      "transformed price RMSE = 218913.7806\n",
      "raw price 1se rule RMSE = 202735.1071\n",
      "transformed price 1se rule RMSE = 283355.9570\n"
     ]
    }
   ],
   "source": [
    "##------범주형 반응변수까지 전부 스케일링함------\n",
    "\n",
    "##----------data----------\n",
    "\n",
    "## fitting scaler with train set\n",
    "numeric_features = list(set(df_train.columns) - set([\"price\", \"date\"])) ## date : 선형이므로 월별로 설정(더미변수 처리)\n",
    "scalr = StandardScaler()\n",
    "\n",
    "## train data\n",
    "X_trans = scalr.fit_transform(pd.concat([df_train.loc[:, numeric_features], pd.get_dummies(train_date[0], drop_first = True, dtype = int)], axis = 1))\n",
    "\n",
    "## test data\n",
    "XX_trans = scalr.transform(pd.concat([df_test.loc[:, numeric_features], pd.get_dummies(test_date[0], drop_first = True, dtype = int)], axis = 1))\n",
    "\n",
    "##----------tuning----------\n",
    "\n",
    "## fitting and cross validation(10-fold)\n",
    "lambdas = 10**np.linspace(2, -4, 100) ## setting grid for plotting\n",
    "kfold = KFold(10, random_state = 14107, shuffle = True)\n",
    "ridgeCV = sklearn.linear_model.ElasticNetCV(alphas = lambdas, l1_ratio = 0, cv = kfold)\n",
    "ridgeCV.fit(X_trans, y)\n",
    "\n",
    "## fitting and cross validation(10-fold)\n",
    "lambdas = 10**np.linspace(3, -5, 100) ## setting grid for plotting\n",
    "kfold = KFold(10, random_state = 14107, shuffle = True)\n",
    "ridgeCV_trans = sklearn.linear_model.ElasticNetCV(alphas = lambdas, l1_ratio = 0, cv = kfold)\n",
    "ridgeCV_trans.fit(X_trans, y_trans)\n",
    "\n",
    "##----------prediction----------\n",
    "\n",
    "## CV optimized predictor : raw price\n",
    "predictr_optim = sklearn.linear_model.ElasticNet(alpha = ridgeCV.alpha_, l1_ratio = 0)\n",
    "predictr_optim.fit(X_trans, y)\n",
    "print(f\"raw price RMSE = {np.mean((yy - predictr_optim.predict(XX_trans))**2)**0.5:.4f}\")\n",
    "\n",
    "## CV optimized predictor : transformed price\n",
    "predictr_optim_trans = sklearn.linear_model.ElasticNet(alpha = ridgeCV_trans.alpha_, l1_ratio = 0)\n",
    "predictr_optim_trans.fit(X_trans, y_trans)\n",
    "print(f\"transformed price RMSE = {np.mean((yy - y_scalr.inverse_transform(predictr_optim.predict(XX_trans).reshape(-1,1)).reshape(-1))**2)**0.5:.4f}\")\n",
    "\n",
    "## 1-se-rule predictor : raw price\n",
    "mse_list = ridgeCV.mse_path_.mean(1)\n",
    "indx = np.where(mse_list == np.min(mse_list))\n",
    "min_mse = mse_list[indx]\n",
    "min_std = ridgeCV.mse_path_.std(1)[indx]\n",
    "simple_indx = np.min(np.where(mse_list <= min_mse + min_std / np.sqrt(10)))\n",
    "predictr_1se = sklearn.linear_model.ElasticNet(alpha = ridgeCV.alphas_[simple_indx], l1_ratio = 0)\n",
    "predictr_1se.fit(X_trans, y)\n",
    "yyhat = predictr_1se.predict(XX_trans)\n",
    "scoring_dict[\"Ridge Regression with 1-se rule\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"raw price 1se rule RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")\n",
    "\n",
    "## 1-se-rule predictor : transformed price\n",
    "mse_list_trans = ridgeCV_trans.mse_path_.mean(1)\n",
    "indx_trans = np.where(mse_list_trans == np.min(mse_list_trans))\n",
    "min_mse_trans = mse_list_trans[indx_trans]\n",
    "min_std_trans = ridgeCV_trans.mse_path_.std(1)[indx]\n",
    "simple_indx_trans = np.min(np.where(mse_list_trans <= min_mse_trans + min_std_trans / np.sqrt(10)))\n",
    "predictr_1se = sklearn.linear_model.ElasticNet(alpha = ridgeCV_trans.alphas_[simple_indx_trans], l1_ratio = 0)\n",
    "predictr_1se.fit(X_trans, y_trans)\n",
    "yyhat = y_scalr.inverse_transform(predictr_1se.predict(XX_trans).reshape(-1,1)).reshape(-1)\n",
    "scoring_dict[\"Ridge Regression with transformed price & 1-se rule\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"transformed price 1se rule RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. Lasso**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 변수 스케일링/하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw price RMSE = 196381.7875\n",
      "transformed price RMSE = 221208.6226\n",
      "raw price 1se rule RMSE = 200062.3972\n",
      "transformed price 1se rule RMSE = 241576.0184\n"
     ]
    }
   ],
   "source": [
    "## fitting scaler with train set\n",
    "numeric_features = list(set(df_train.columns) - set([\"price\", \"date\", \"waterfront\"])) ## date : 선형이므로 월별로 설정(더미변수 처리)\n",
    "scalr = StandardScaler()\n",
    "y_scalr = PowerTransformer()\n",
    "standarized_features = scalr.fit_transform(df_train.loc[:, numeric_features])\n",
    "\n",
    "## train data\n",
    "X_trans = np.concatenate([standarized_features, np.asarray(pd.get_dummies(train_date[0], drop_first = True, dtype = int).assign(waterfront = df_train.waterfront))], axis = 1) # features\n",
    "y_trans = np.asarray(y_scalr.fit_transform(pd.DataFrame(df_train.price))).reshape(-1) ## scaled target\n",
    "\n",
    "## test data\n",
    "XX_trans = np.concatenate([scalr.transform(df_test.loc[:, numeric_features]), np.asarray(pd.get_dummies(test_date[0], drop_first = True, dtype = int).assign(waterfront = df_test.waterfront))], axis = 1)\n",
    "yy_trans = np.asarray(y_scalr.transform(pd.DataFrame(df_test.price))).reshape(-1)\n",
    "\n",
    "\n",
    "## fitting and cross validation(10-fold)\n",
    "lambdas = 10**np.linspace(1, -5, 100) ## setting grid for plotting\n",
    "kfold = KFold(10, random_state = 14107, shuffle = True)\n",
    "LassoCV = sklearn.linear_model.ElasticNetCV(alphas = lambdas, l1_ratio = 0, cv = kfold)\n",
    "LassoCV.fit(X_trans, y)\n",
    "\n",
    "## fitting and cross validation(10-fold)\n",
    "lambdas = 10**np.linspace(0, -5, 100) ## setting grid for plotting\n",
    "kfold = KFold(10, random_state = 14107, shuffle = True)\n",
    "LassoCV_trans = sklearn.linear_model.ElasticNetCV(alphas = lambdas, l1_ratio = 0, cv = kfold)\n",
    "LassoCV_trans.fit(X_trans, y_trans)\n",
    "\n",
    "##----------prediction----------\n",
    "\n",
    "## CV optimized predictor : raw price\n",
    "predictr_optim = sklearn.linear_model.ElasticNet(alpha = LassoCV.alpha_, l1_ratio = 0)\n",
    "predictr_optim.fit(X_trans, y)\n",
    "scoring_dict[\"Lasso Regression\"] = np.mean((yy - predictr_optim.predict(XX_trans))**2)**0.5\n",
    "print(f\"raw price RMSE = {np.mean((yy - predictr_optim.predict(XX_trans))**2)**0.5:.4f}\")\n",
    "\n",
    "## CV optimized predictor : transformed price\n",
    "predictr_optim_trans = sklearn.linear_model.ElasticNet(alpha = LassoCV_trans.alpha_, l1_ratio = 0)\n",
    "predictr_optim_trans.fit(X_trans, y_trans)\n",
    "scoring_dict[\"Lasso Regression with transformed price\"] = np.mean((yy - y_scalr.inverse_transform(predictr_optim.predict(XX_trans).reshape(-1,1)).reshape(-1))**2)**0.5\n",
    "print(f\"transformed price RMSE = {np.mean((yy - y_scalr.inverse_transform(predictr_optim.predict(XX_trans).reshape(-1,1)).reshape(-1))**2)**0.5:.4f}\")\n",
    "\n",
    "## 1-se-rule predictor : raw price\n",
    "mse_list = LassoCV.mse_path_.mean(1)\n",
    "indx = np.where(mse_list == np.min(mse_list))\n",
    "min_mse = mse_list[indx]\n",
    "min_std = LassoCV.mse_path_.std(1)[indx]\n",
    "simple_indx = np.min(np.where(mse_list <= min_mse + min_std / np.sqrt(10)))\n",
    "predictr_1se = sklearn.linear_model.ElasticNet(alpha = LassoCV.alphas_[simple_indx], l1_ratio = 0)\n",
    "predictr_1se.fit(X_trans, y)\n",
    "yyhat = predictr_1se.predict(XX_trans)\n",
    "scoring_dict[\"Lasso Regression with 1-se rule\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"raw price 1se rule RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")\n",
    "\n",
    "## 1-se-rule predictor : transformed price\n",
    "mse_list_trans = LassoCV_trans.mse_path_.mean(1)\n",
    "indx_trans = np.where(mse_list_trans == np.min(mse_list_trans))\n",
    "min_mse_trans = mse_list_trans[indx_trans]\n",
    "min_std_trans = LassoCV_trans.mse_path_.std(1)[indx]\n",
    "simple_indx_trans = np.min(np.where(mse_list_trans <= min_mse_trans + min_std_trans / np.sqrt(10)))\n",
    "predictr_1se = sklearn.linear_model.ElasticNet(alpha = LassoCV_trans.alphas_[simple_indx_trans], l1_ratio = 0)\n",
    "predictr_1se.fit(X_trans, y_trans)\n",
    "yyhat = y_scalr.inverse_transform(predictr_1se.predict(XX_trans).reshape(-1,1)).reshape(-1)\n",
    "scoring_dict[\"Lasso Regression with transformed price & 1-se rule\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"transformed price 1se rule RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n",
    "LassoCV_fig, axs = plt.subplots(1, 2, figsize=(16,8))\n",
    "axs[0].errorbar(-np.log(LassoCV.alphas_), LassoCV.mse_path_.mean(1),\n",
    "            yerr=LassoCV.mse_path_.std(1) / np.sqrt(10))\n",
    "axs[0].axvline(-np.log(LassoCV.alpha_), c='k', ls='--')\n",
    "axs[0].axhline(min_mse + min_std / np.sqrt(10), c = 'k', ls = '--')\n",
    "axs[0].set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "axs[0].set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "axs[0].scatter(-np.log(LassoCV.alphas_[simple_indx]), mse_list[simple_indx],\n",
    "           color = \"red\", s = 15, label = \"1-se rule selection\", zorder = 5)\n",
    "axs[0].set_title(\"반응변수 변환이 없는 경우 CV MSE와 그 표준오차\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].errorbar(-np.log(LassoCV_trans.alphas_), LassoCV_trans.mse_path_.mean(1),\n",
    "            yerr=LassoCV_trans.mse_path_.std(1) / np.sqrt(10))\n",
    "axs[1].axvline(-np.log(LassoCV_trans.alpha_), c='k', ls='--')\n",
    "axs[1].axhline(min_mse_trans + min_std_trans / np.sqrt(10), c = 'k', ls = '--')\n",
    "axs[1].set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "axs[1].set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "axs[1].scatter(-np.log(LassoCV_trans.alphas_[simple_indx_trans]), mse_list_trans[simple_indx_trans],\n",
    "           color = \"red\", s = 15, label = \"1-se rule selection\", zorder = 5)\n",
    "axs[1].set_title(\"반응변수를 파워변환 한 경우 CV MSE와 그 표준오차\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## showing parameter\n",
    "print(f'선택된 lambda(raw) = {LassoCV.alpha_ : .5f}, {LassoCV.alphas_[simple_indx] : .5f}')\n",
    "print(f\"선택된 lambda(powertransform) = {LassoCV_trans.alpha_ : .5f}, {LassoCV_trans.alphas_[simple_indx_trans] : .5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 선형 모형 간 성능 비교**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dict = {k:float(v) for k, v in scoring_dict.items() if ((\"Linear\" in k) or (\"Ridge\" in k) or (\"Lasso\" in k)) and (\"Reduction\" not in k)}\n",
    "df_score = pd.DataFrame({\"method\" : linear_dict.keys(), \"score\" : linear_dict.values()}).iloc[[1,0,2,4,3,5,6,8,7,9]]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = df_score.score,\n",
    "        y = df_score.method,\n",
    "        text = df_score.score,\n",
    "        orientation = \"h\",\n",
    "        texttemplate = \"%{text:.4f}\",\n",
    "        marker_line=dict(width=5, color='black')\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(height = 800, title = dict(text=\"선형 모형 적합결과의 비교(RMSE)\", font=dict(size=30), x = 0.5, y = 0.95))\n",
    "fig[\"data\"][0][\"marker\"][\"color\"] = [\"skyblue\"]*2 + [\"green\"]*4 + [\"blue\"]*4\n",
    "fig[\"data\"][0][\"marker\"][\"line\"][\"color\"] = [\"red\", \"skyblue\"] + [\"red\"] + [\"green\"]*3 + [\"red\"] + [\"blue\"]*3\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. 비선형 모형 적용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 시각화 및 $\\lambda$ 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "X = df_train.drop([\"date\", \"price\"], axis = 1).assign(days = train_date[1]) ## 일별 자료\n",
    "y = df_train.price\n",
    "\n",
    "XX = df_test.drop([\"date\", \"price\"], axis = 1).assign(days = test_date[1])\n",
    "yy = df_test.price\n",
    "\n",
    "## lambda grid\n",
    "lams = 10**np.linspace(-1, 4, 50)\n",
    "kfold = KFold(5, random_state = 14107, shuffle = True)\n",
    "\n",
    "## 초기화\n",
    "mean_scores = []\n",
    "std_scores = []\n",
    "\n",
    "## CV\n",
    "for i, lam in enumerate(lams):\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, valid_idx in kfold.split(X):\n",
    "        X_train, X_valid = X.to_numpy()[train_idx], X.to_numpy()[valid_idx]\n",
    "        y_train, y_valid = y.to_numpy()[train_idx], y.to_numpy()[valid_idx]\n",
    "\n",
    "        gam = LinearGAM(lam=lam).fit(X_train, y_train)\n",
    "        yyhat = gam.predict(X_valid)\n",
    "        rmse = np.mean((y_valid - yyhat)**2)**0.5\n",
    "        scores.append(rmse)\n",
    "\n",
    "    mean_scores.append(np.mean(scores))\n",
    "    std_scores.append(np.std(scores))\n",
    "\n",
    "    print(f\"{i} cycle rooped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimized value\n",
    "indx = np.where(mean_scores == np.min(mean_scores))[0][0]\n",
    "min_mse = mean_scores[indx]\n",
    "min_std = std_scores[indx]\n",
    "simple_indx = np.max(np.where(mean_scores <= min_mse + min_std / np.sqrt(5)))\n",
    "\n",
    "## plotting\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lams), mean_scores, yerr = std_scores/np.sqrt(5))\n",
    "ax.axvline(-np.log(lams[indx]), c='k', ls='--')\n",
    "ax.axhline(min_mse + min_std / np.sqrt(5), c = 'k', ls = '--')\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.scatter(-np.log(lams[simple_indx]), mean_scores[simple_indx],\n",
    "           color = \"red\", s = 15, label = \"1-se rule selection\", zorder = 5)\n",
    "ax.set_title(f\"GAM에서 $\\lambda$ 값을 변환시켜갈 때의 CV MSE\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## optimal lambda\n",
    "optim_lambda = lams[indx]\n",
    "optim_1se_lambda = lams[simple_indx]\n",
    "print(f\"Optimal : {optim_lambda:.4f}\")\n",
    "print(f\"1-se rule : {optim_1se_lambda:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 156864.5731\n",
      "RMSE = 165829.6970\n"
     ]
    }
   ],
   "source": [
    "## test RMSE 산출\n",
    "gam = LinearGAM(lam = optim_lambda)\n",
    "gam.fit(X, y)\n",
    "scoring_dict[\"GAM\"] = np.mean((yy - gam.predict(XX))**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - gam.predict(XX))**2)**0.5:.4f}\")\n",
    "\n",
    "gam = LinearGAM(lam = optim_1se_lambda)\n",
    "gam.fit(X, y)\n",
    "scoring_dict[\"GAM with 1-se rule\"] = np.mean((yy - gam.predict(XX))**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - gam.predict(XX))**2)**0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 범주형 설명변수 `waterfront`를 따로 처리하는 경우(성능이 더 떨어졌음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lambda grid\n",
    "lams = 10**np.linspace(-1, 4, 50)\n",
    "kfold = KFold(5, random_state = 14107, shuffle = True)\n",
    "\n",
    "## 초기화\n",
    "mean_scores = []\n",
    "std_scores = []\n",
    "\n",
    "## CV\n",
    "for i, lam in enumerate(lams):\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, valid_idx in kfold.split(X):\n",
    "        X_train, X_valid = X_trans[train_idx], X_trans[valid_idx]\n",
    "        y_train, y_valid = y.to_numpy()[train_idx], y.to_numpy()[valid_idx]\n",
    "\n",
    "        ## 6번째 변수, waterfront를 범주형으로 처리\n",
    "        gam = LinearGAM(s(0) + s(1) + s(2) + s(3) + s(4) + f(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13) + s(14) + s(15) + s(16) + s(17) + s(18), lam = lam)\n",
    "        gam.fit(X_train, y_train)\n",
    "        yyhat = gam.predict(X_valid)\n",
    "        rmse = np.mean((y_valid - yyhat)**2)**0.5\n",
    "        scores.append(rmse)\n",
    "\n",
    "    mean_scores.append(np.mean(scores))\n",
    "    std_scores.append(np.std(scores))\n",
    "\n",
    "    print(f\"{i} cycle rooped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimized value\n",
    "indx = np.where(mean_scores == np.min(mean_scores))[0][0]\n",
    "min_mse = mean_scores[indx]\n",
    "min_std = std_scores[indx]\n",
    "simple_indx = np.max(np.where(mean_scores <= min_mse + min_std / np.sqrt(5)))\n",
    "\n",
    "## plotting\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lams), mean_scores, yerr = std_scores/np.sqrt(5))\n",
    "ax.axvline(-np.log(lams[indx]), c='k', ls='--')\n",
    "ax.axhline(min_mse + min_std / np.sqrt(5), c = 'k', ls = '--')\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.scatter(-np.log(lams[simple_indx]), mean_scores[simple_indx],\n",
    "           color = \"red\", s = 15, label = \"1-se rule selection\", zorder = 5)\n",
    "ax.set_title(f\"GAM에서 $\\lambda$ 값을 변환시켜갈 때의 CV MSE\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## optimal lambda\n",
    "optim_lambda = lams[indx]\n",
    "optim_1se_lambda = lams[simple_indx]\n",
    "print(f\"Optimal : {optim_lambda:.4f}\")\n",
    "print(f\"1-se rule : {optim_1se_lambda:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 159278.7315\n",
      "RMSE = 163501.3002\n"
     ]
    }
   ],
   "source": [
    "## test RMSE 산출\n",
    "gam = LinearGAM(lam = optim_lambda)\n",
    "gam.fit(X, y)\n",
    "print(f\"RMSE = {np.mean((yy - gam.predict(XX))**2)**0.5:.4f}\")\n",
    "\n",
    "gam = LinearGAM(lam = optim_1se_lambda)\n",
    "gam.fit(X, y)\n",
    "print(f\"RMSE = {np.mean((yy - gam.predict(XX))**2)**0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. 나무 모형**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 훈련 데이터에서 CV로 최적의 prunning을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "X = df_train.drop([\"date\", \"price\"], axis = 1).assign(days = train_date[1]) ## 일별 자료\n",
    "y = df_train.price\n",
    "\n",
    "XX = df_test.drop([\"date\", \"price\"], axis = 1).assign(days = test_date[1])\n",
    "yy = df_test.price\n",
    "\n",
    "## predictor\n",
    "predictr = DecisionTreeRegressor() ## criterion = squared_error\n",
    "ccp_path = predictr.cost_complexity_pruning_path(X, y)\n",
    "kfold = KFold(5, random_state = 14107, shuffle = True)\n",
    "\n",
    "validatr = GridSearchCV(predictr, {'ccp_alpha' : ccp_path.ccp_alphas},\n",
    "                        refit = True, cv = kfold, scoring = \"neg_root_mean_squared_error\", verbose = 2)\n",
    "validatr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 172828.85210206837\n",
      "number of leaves = 436\n",
      "best param : {'ccp_alpha': 11967239.867225198}\n"
     ]
    }
   ],
   "source": [
    "best_predictr = validatr.best_estimator_\n",
    "scoring_dict[\"Tree CV\"] = np.mean((yy - best_predictr.predict(XX))**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - best_predictr.predict(XX))**2)**0.5}\")\n",
    "print(f\"number of leaves = {best_predictr.get_n_leaves()}\")\n",
    "print(f\"best param : {validatr.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 최적모형과 제일 복잡한 모형과의 성능지표 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictr = DecisionTreeRegressor()\n",
    "full_predictr.fit(X, y)\n",
    "rmse = np.mean((yy - full_predictr.predict(XX))**2)**0.5\n",
    "\n",
    "df_score = pd.DataFrame({\"Method\" : [\"Tree CV\", \"Full Tree\", \"GAM\"], \"score\" : [scoring_dict[\"Tree CV\"], rmse, scoring_dict[\"GAM\"]]})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = df_score.score,\n",
    "        y = df_score.Method,\n",
    "        text = df_score.score,\n",
    "        texttemplate = \"%{text:.4f}\",\n",
    "        orientation = \"h\",\n",
    "        marker_line=dict(width=5, color='black')\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(categoryorder = \"total descending\")\n",
    "fig[\"data\"][0][\"marker\"][\"color\"] = [\"skyblue\", \"skyblue\", \"skyblue\"]\n",
    "fig[\"data\"][0][\"marker\"][\"line\"][\"color\"] = [\"red\", \"skyblue\", \"skyblue\"]\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 적합된 트리 모형 시각화(max_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "X = df_train.drop([\"date\", \"price\"], axis = 1).assign(days = train_date[1]) ## 일별 자료\n",
    "y = df_train.price\n",
    "\n",
    "XX = df_test.drop([\"date\", \"price\"], axis = 1).assign(days = test_date[1])\n",
    "yy = df_test.price\n",
    "\n",
    "predictr_for_viz = DecisionTreeRegressor(max_depth = 3)\n",
    "predictr_for_viz.fit(X, y)\n",
    "viz = dtreeviz.model(predictr_for_viz, X, y, target_name = \"price\", feature_names = X.columns)\n",
    "viz.view(fontname = \"NanumGothic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. 부스팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "X = df_train.drop([\"date\", \"price\"], axis = 1).assign(days = train_date[1]) ## 일별 자료\n",
    "y = df_train.price\n",
    "\n",
    "XX = df_test.drop([\"date\", \"price\"], axis = 1).assign(days = test_date[1])\n",
    "yy = df_test.price\n",
    "\n",
    "## params\n",
    "fit_params = {\n",
    "    'early_stopping_rounds': 10, ## 성능 개선이 없을 시 종료 라운드\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "search_space = {\n",
    "    'learning_rate': (0.001, 0.1), ## 학습률\n",
    "    'n_estimators': (100, 1000), ## 트리 수\n",
    "    'gamma': (1e-1, 10000, \"log-uniform\"), ## 노드 분할 시 최소 손실 감소량\n",
    "    'max_depth': (1, 10), ## 트리 깊이\n",
    "    'min_child_weight': (1e-2, 100, \"log-uniform\"), ## 헤시안의 최소값\n",
    "    'colsample_bytree': (0.2, 0.7), ## 각 트리 구성 시 사용하는 열의 비율\n",
    "    'subsample': (0.5, 1.0), ## 데이터 서브 샘플링\n",
    "    'sampling_method': [\"uniform\", \"gradient_based\"], ## 서브 샘플링 방법\n",
    "    'lambda': (1e-1, 10000, \"log-uniform\"), ## 가중치 L2 표준화 계수\n",
    "    'alpha': (1e-2, 1000, \"log-uniform\") ## 가중치 L1 표준화 계수\n",
    "}\n",
    "\n",
    "kfold = KFold(4, random_state = 14107, shuffle = True)\n",
    "\n",
    "## optimizr\n",
    "predictr = xgb.XGBRegressor(tree_method = \"gpu_hist\", device = \"cuda\")\n",
    "optimizr = BayesSearchCV(\n",
    "    estimator=predictr,\n",
    "    search_spaces=search_space,\n",
    "    fit_params=fit_params,\n",
    "    cv=kfold,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    random_state=14107,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "optimizr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 107541.7772014463\n"
     ]
    }
   ],
   "source": [
    "## best parameter set 확인\n",
    "# print(optimizr.best_estimator_.get_params())\n",
    "\n",
    "## rmse 계산\n",
    "best_predictr = xgb.XGBRegressor(**optimizr.best_estimator_.get_params())\n",
    "best_predictr.fit(X, y)\n",
    "scoring_dict[\"XGBoost CV\"] = np.mean((yy - best_predictr.predict(XX))**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - best_predictr.predict(XX))**2)**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Features importance 산출 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\"features\" : best_predictr.feature_names_in_, \"importances\" : best_predictr.feature_importances_})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = importances.importances,\n",
    "        y = importances.features,\n",
    "        text = importances.importances,\n",
    "        texttemplate = \"%{text:.4f}\",\n",
    "        orientation = \"h\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(width = 1200, height = 900, title=dict(text=\"최적 모형의 Feature Importances\", font=dict(size=30), x = 0.5, y = 0.95))\n",
    "fig.update_yaxes(categoryorder = \"total ascending\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 첫 번째 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 반응변수 구간 분할\n",
    "X = df_train[[\"long\", \"lat\"]]\n",
    "y = df_train.price.map(lambda x : x >= df_train.price.median()).astype(int)\n",
    "\n",
    "XX = df_test[[\"long\", \"lat\"]]\n",
    "yy = df_test.price.map(lambda x : x >= df_train.price.median()).astype(int)\n",
    "\n",
    "## hyperparameter tuning\n",
    "svm_rbf = SVC()\n",
    "kfold = KFold(5, random_state=0, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(svm_rbf, {'C':[0.1,1,10,100,1000], 'gamma':[0.5,1,2,3,4]}, refit=True, cv=kfold, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "\n",
    "## evaluation\n",
    "best_svm = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 두 번째 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10000, 'gamma': 1000.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## hyperparameter tuning\n",
    "svm_rbf = SVC()\n",
    "kfold = KFold(5, random_state=0, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(svm_rbf, {'C': [1000, 5000, 10000], 'gamma': 10**np.linspace(0, 3, 5)}, refit=True, cv=kfold, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "\n",
    "## evaluation\n",
    "best_svm = grid.best_estimator_\n",
    "yyhat = best_svm.predict(XX)\n",
    "confusion_matrix(yyhat, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시각화 1 : c = 1000\n",
    "gammas = [1, 10, 100, 1000]\n",
    "models = [SVC(kernel='rbf', gamma = i, C = 1000) for i in gammas]\n",
    "models = [clf.fit(X, y) for clf in models]\n",
    "titles = [f\"gamma = {i}\" for i in gammas]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize = (16, 3.5))\n",
    "\n",
    "for clf, title, ax in zip(models, titles, axs.flatten()) :\n",
    "        disp = DecisionBoundaryDisplay.from_estimator(\n",
    "                clf,\n",
    "                X,\n",
    "                response_method=\"predict\",\n",
    "                cmap=plt.cm.coolwarm,\n",
    "                alpha=0.8,\n",
    "                ax=ax\n",
    "        )\n",
    "\n",
    "        ax.scatter(X.long, X.lat, c = y, cmap = plt.cm.coolwarm, s = 20, edgecolors = \"k\")\n",
    "        ax.set_xlim([X.long.min(), X.long.max()])\n",
    "        ax.set_ylim([X.lat.min(), X.lat.max()])\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시각화 2 : c = 10000\n",
    "gammas = [1, 10, 100, 1000]\n",
    "models = [SVC(kernel='rbf', gamma = i, C = 10000) for i in gammas]\n",
    "models = [clf.fit(X, y) for clf in models]\n",
    "titles = [f\"gamma = {i}\" for i in gammas]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize = (16, 3.5))\n",
    "\n",
    "for clf, title, ax in zip(models, titles, axs.flatten()) :\n",
    "        disp = DecisionBoundaryDisplay.from_estimator(\n",
    "                clf,\n",
    "                X,\n",
    "                response_method=\"predict\",\n",
    "                cmap=plt.cm.coolwarm,\n",
    "                alpha=0.8,\n",
    "                ax=ax\n",
    "        )\n",
    "\n",
    "        ax.scatter(X.long, X.lat, c = y, cmap = plt.cm.coolwarm, s = 20, edgecolors = \"k\")\n",
    "        ax.set_xlim([X.long.min(), X.long.max()])\n",
    "        ax.set_ylim([X.lat.min(), X.lat.max()])\n",
    "        ax.set_title(title)\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. 비지도학습 : PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 위도/경도를 KPCA 해본 결과 시각화(components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = np.logspace(-3, 4, 8)\n",
    "fig = make_subplots(rows = 2, cols = 4, subplot_titles = [f\"gamma = {gamma}\" for gamma in gammas])\n",
    "\n",
    "for i, gamma in enumerate(gammas) :\n",
    "    kpca = KernelPCA(kernel = \"rbf\", gamma = gamma, n_components = 2)\n",
    "    trans_location = kpca.fit_transform(X[[\"long\", \"lat\"]])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = trans_location[:, 0],\n",
    "            y = trans_location[:, 1],\n",
    "            marker_color = df_train.price,\n",
    "            mode = \"markers\",\n",
    "            marker=dict(size=2),\n",
    "            marker_colorscale = \"bluyl\"\n",
    "        ),\n",
    "        row = 1+i//4, col = 1+i%4\n",
    "    )\n",
    "    \n",
    "fig.show() ## 망함, 애초에 구조가 애매함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 중심지(최대 거래가격)와의 거리를 설명변수로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변환\n",
    "central_location = df_train.loc[df_train.price == df_train.price.max(), [\"long\", \"lat\"]]\n",
    "central_long, central_lat = central_location.iloc[0, 0], central_location.iloc[0, 1]\n",
    "location = df_train[[\"long\", \"lat\"]]\n",
    "\n",
    "df_distance = location.assign(long_sq = location.long.map(lambda x : (x-central_long)**2)).assign(lat_sq = location.lat.map(lambda x : (x-central_lat)**2))\\\n",
    "    .assign(distance = lambda _df : (_df.long_sq + _df.lat_sq)**0.5)\n",
    "\n",
    "## 시각화\n",
    "fig = make_subplots(rows = 1, cols = 2, subplot_titles = [\"distance\", \"price\"])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = df_distance.long,\n",
    "        y = df_distance.lat,\n",
    "        marker_color = -df_distance.distance, ## 색상 통일시키기 위해 음수로\n",
    "        mode = \"markers\",\n",
    "        marker=dict(size=2),\n",
    "        marker_colorscale = \"bluyl\"\n",
    "    ),\n",
    "    row = 1, col = 1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = df_distance.long,\n",
    "        y = df_distance.lat,\n",
    "        marker_color = df_train.price,\n",
    "        mode = \"markers\",\n",
    "        marker=dict(size=2),\n",
    "        marker_colorscale = \"bluyl\"\n",
    "    ),\n",
    "    row = 1, col = 2\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 192870.6356\n"
     ]
    }
   ],
   "source": [
    "## 설명변수 차원 축소(위도/경도 -> 중심으로부터의 거리)\n",
    "X = pd.get_dummies(df_train.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = train_date[0]).assign(distance = (df_train.long.map(lambda x : (x - central_long)**2) + df_train.lat.map(lambda x : (x - central_lat)**2))**0.5), drop_first = True, dtype = int)\n",
    "y = df_train.price\n",
    "\n",
    "XX = pd.get_dummies(df_test.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = test_date[0]).assign(distance = (df_test.long.map(lambda x : (x - central_long)**2) + df_test.lat.map(lambda x : (x - central_lat)**2))**0.5), drop_first = True, dtype = int)\n",
    "yy = df_test.price\n",
    "\n",
    "## 선형 모형 적합\n",
    "\n",
    "## predictor\n",
    "predictr = sklearn.linear_model.LinearRegression()\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## prediction\n",
    "yyhat = predictr.predict(XX)\n",
    "\n",
    "## evaluation\n",
    "scoring_dict[\"Linear Regression with Reduction\"] = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 211999.1422\n"
     ]
    }
   ],
   "source": [
    "## 변수 제거로 인해 발생한 효과는 아닌지 확인\n",
    "X = pd.get_dummies(df_train.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = train_date[0]), drop_first = True, dtype = int)\n",
    "y = df_train.price\n",
    "\n",
    "XX = pd.get_dummies(df_test.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = test_date[0]), drop_first = True, dtype = int)\n",
    "yy = df_test.price\n",
    "\n",
    "## 선형 모형 적합\n",
    "\n",
    "## predictor\n",
    "predictr = sklearn.linear_model.LinearRegression()\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## prediction\n",
    "yyhat = predictr.predict(XX)\n",
    "\n",
    "## evaluation\n",
    "rmse2 = np.mean((yy - yyhat)**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy - yyhat)**2)**0.5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` PCA 및 PCR / 사용할 주성분의 수 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "X = pd.get_dummies(df_train.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = train_date[0]).assign(distance = (df_train.long.map(lambda x : (x - central_long)**2) + df_train.lat.map(lambda x : (x - central_lat)**2))**0.5), drop_first = True, dtype = int)\n",
    "y = df_train.price\n",
    "\n",
    "XX = pd.get_dummies(df_test.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = test_date[0]).assign(distance = (df_test.long.map(lambda x : (x - central_long)**2) + df_test.lat.map(lambda x : (x - central_lat)**2))**0.5), drop_first = True, dtype = int)\n",
    "yy = df_test.price\n",
    "\n",
    "## 초기화\n",
    "mean_scores = []\n",
    "std_scores = []\n",
    "\n",
    "## CV\n",
    "for i in range(28) :\n",
    "    scores = []\n",
    "    pca = PCA(n_components = i+1)\n",
    "    pca.fit(X)\n",
    "    \n",
    "    X_reduction = pca.transform(X)\n",
    "    XX_reduction = pca.transform(XX)\n",
    "    \n",
    "    kfold = KFold(10, random_state = 14107, shuffle = True)\n",
    "    \n",
    "    for train_idx, valid_idx in kfold.split(X_reduction):\n",
    "        X_train, X_valid = X_reduction[train_idx], X_reduction[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        predictr = sklearn.linear_model.LinearRegression()\n",
    "        predictr.fit(X_train, y_train)\n",
    "        yyhat = predictr.predict(X_valid)\n",
    "        rmse = np.mean((y_valid - yyhat)**2)**0.5\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    mean_scores.append(np.mean(scores))\n",
    "    std_scores.append(np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimized value\n",
    "indx = np.where(mean_scores == np.min(mean_scores))[0][0]\n",
    "min_mse = mean_scores[indx]\n",
    "min_std = std_scores[indx]\n",
    "simple_indx = np.min(np.where(mean_scores <= min_mse + min_std / np.sqrt(5)))\n",
    "\n",
    "## plotting\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.errorbar(list(range(1, 29)), mean_scores, yerr = std_scores/np.sqrt(5))\n",
    "ax.axvline(list(range(1, 29))[indx], c='k', ls='--')\n",
    "ax.axhline(min_mse + min_std / np.sqrt(5), c = 'k', ls = '--')\n",
    "ax.set_xlabel('PC$_i$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20)\n",
    "ax.scatter(list(range(1, 29))[simple_indx], mean_scores[simple_indx],\n",
    "           color = \"red\", s = 15, label = \"1-se rule selection\", zorder = 5)\n",
    "ax.set_title(f\"PC$_i$에서의 CV MSE\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## optimal lambda\n",
    "optim_lambda = list(range(1, 29))[indx] ## 26\n",
    "optim_1se_lambda = list(range(1, 29))[simple_indx] ## 25\n",
    "print(f\"Optimal : {optim_lambda:.4f}\")\n",
    "print(f\"1-se rule : {optim_1se_lambda:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 192850.14039133323\n",
      "RMSE = 195149.43103947132\n"
     ]
    }
   ],
   "source": [
    "## data\n",
    "X = pd.get_dummies(df_train.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = train_date[0]).assign(distance = (df_train.long.map(lambda x : (x - central_long)**2) + df_train.lat.map(lambda x : (x - central_lat)**2))**0.5), drop_first = True, dtype = int)\n",
    "y = df_train.price\n",
    "\n",
    "XX = pd.get_dummies(df_test.drop([\"date\", \"price\", \"lat\", \"long\"], axis = 1).assign(month = test_date[0]).assign(distance = (df_test.long.map(lambda x : (x - central_long)**2) + df_test.lat.map(lambda x : (x - central_lat)**2))**0.5), drop_first = True, dtype = int)\n",
    "yy = df_test.price\n",
    "\n",
    "pca1 = PCA(n_components = 26)\n",
    "X_reduction1 = pca1.fit_transform(X)\n",
    "XX_reduction1 = pca1.transform(XX)\n",
    "\n",
    "pca2 = PCA(n_components = 25)\n",
    "X_reduction2 = pca2.fit_transform(X)\n",
    "XX_reduction2 = pca2.transform(XX)\n",
    "\n",
    "## 적합 및 평가\n",
    "predictr1 = sklearn.linear_model.LinearRegression()\n",
    "predictr1.fit(X_reduction1, y)\n",
    "yyhat1 = predictr1.predict(XX_reduction1)\n",
    "scoring_dict[\"PCR with 26th PC\"] = np.mean((yy-yyhat1)**2)**0.5\n",
    "print(f\"RMSE = {np.mean((yy-yyhat1)**2)**0.5}\")\n",
    "\n",
    "predictr2 = sklearn.linear_model.LinearRegression()\n",
    "predictr2.fit(X_reduction2, y)\n",
    "yyhat2 = predictr2.predict(XX_reduction2)\n",
    "print(f\"RMSE = {np.mean((yy-yyhat2)**2)**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 선형 모형 간 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scoring = pd.DataFrame({\"Method\" : scoring_dict.keys(), \"test MSE\" : scoring_dict.values()}).sort_values(\"test MSE\", ascending = False).reset_index(drop = True)\n",
    "tidy = df_scoring.iloc[[4, 5, 6, 7], :]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = tidy[\"test MSE\"],\n",
    "        y = tidy.Method,\n",
    "        text = tidy[\"test MSE\"],\n",
    "        texttemplate = \"%{text:.4f}\",\n",
    "        orientation = \"h\",\n",
    "        marker_line=dict(width=5, color='black')\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(categoryorder = \"total ascending\")\n",
    "fig[\"data\"][0][\"marker\"][\"color\"] = [\"skyblue\", \"skyblue\", \"skyblue\", \"skyblue\"]\n",
    "fig[\"data\"][0][\"marker\"][\"line\"][\"color\"] = [\"skyblue\", \"skyblue\", \"red\", \"red\"]\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. 결론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 방법론 별 성능 지표 비교 : RMSE\n",
    "df_score = pd.DataFrame({\"method\" : scoring_dict.keys(), \"score\" : scoring_dict.values()}).iloc[[1, 2, 12, 6, 9, 8]]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x = df_score.score,\n",
    "        y = df_score.method,\n",
    "        text = df_score.score,\n",
    "        orientation = \"h\",\n",
    "        texttemplate = \"%{text:.4f}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(categoryorder = \"total ascending\")\n",
    "fig.update_layout(height = 800, title = dict(text=\"각 방법 별 최적 모형에서의 적합 결과 비교(RMSE)\", font=dict(size=30), x = 0.5, y = 0.95))\n",
    "fig[\"data\"][0][\"marker\"][\"color\"] = [\"skyblue\"]*5 + [\"orange\"]\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
