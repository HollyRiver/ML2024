{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 기하학 기반의 분류 모형.\n",
    "\n",
    "* 확률적 모형이 아니여도 문제를 풀 수 있다라는 뭐시기. 나중엔 이것도 확률과 뭐시기...\n",
    "\n",
    "> 확률이라는 게 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초평면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그룹을 나누는 선을 정하는 문제.\n",
    "* 선 위에 있는지, 선 가운데에 있는지(분류 못함), 선 아래에 있는지.\n",
    "\n",
    "* decision boundary를 구할 때, 구분선과 개별 점 간의 거리를 계산하여 각 점과의 거리 중 가장 작은 것을 margin으로 정함.\n",
    "\n",
    "> margin을 가장 크게 하는 구분선을 설정함. 이 때, 모든 데이터 포인트가 필요하지 않고 경계에 가까이 있는 데이터만 사용되게 됨.\n",
    ">\n",
    "> margin을 구할 때 사용하는 데이터 포인트들을 support vector라고 함.\n",
    "\n",
    "* 실제로 사용하는 데이터 포인트들은 상당히 적음. 데이터의 크기가 상당히 커도 계산량이 적음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. support vector인지 식별하는 알고리즘 적용\n",
    "2. margin을 계산하여 이를 가장 크게 하는 decision boundary를 식별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Real data\n",
    "\n",
    "* 각 그룹이 완벽하게 나뉘지 않고 섞여있을 수가 있음.\n",
    "\n",
    "해결법\n",
    "> embedding : 데이터를 어떻게 변환을 하여 decision boundary가 식별 될 수 있도록 만듦. -> kernel 응용.\n",
    ">\n",
    "> soft margin : margin을 maximum으로 만들되, 애초에 데이터가 margin 안으로 들어갈 수 있도록 허용을 하겠다. 넘나드는 것을 허용하겠다. -> 가중치를 하이퍼파라미터로 먹어서 하면 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리\n",
    "\n",
    "* 두 개의 레이블이 다른 데이터의 사이(거리)가 벌어져있는 경우를 생각하자. 이 때, 두 개의 데이터를 나눌 때 margin을 최대로 하는 decision boundary를 찾는다.\n",
    "\n",
    "* 두 레이블이 완벽히 나뉘지 않을 땐, 데이터를 임베딩하거나 margin 안쪽으로 데이터가 넘나드는 것을 일부 허용하여 문제를 풀이한다.\n",
    "\n",
    "* 의미 있는 데이터 : 서포트 벡터만 가지괴 모형을 구성하다보니, 속도가 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이론 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초평면 위에 있다\n",
    "\n",
    "$$\\beta_0 + \\beta_1 x_{i1} + \\cdots \\beta_p x_{ip} > 0 ~ \\text{if}~ y_i = 1$$\n",
    "\n",
    "초평면 아래에 있다\n",
    "\n",
    "$$\\beta_0 + \\beta_1 x_{i1} + \\cdots \\beta_p x_{ip} < 0 ~ \\text{if}~ y_i = -1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seperating hyperplane은 무한이 많이 존재한다. 하지만 관측치들이 가능하면 decision boundary로부터 멀리 떨어지도록 하는 것이 좋다.\n",
    "\n",
    "* 훈련자료와 decision boundary의 최소 거리를 margin이라 한다.\n",
    "\n",
    "* 잘 분류가 되었다면 test data에서의 error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
