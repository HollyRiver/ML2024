{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948c238e-b2fa-4a7d-a6b3-0e296077aa52",
   "metadata": {},
   "source": [
    "**시험문제**\n",
    "\n",
    "코드는 거의 안나올거\n",
    "\n",
    "\n",
    "1. OX(거의 나오지 않을 것 같음)\n",
    "\n",
    "2. 간단한 단답형(개념에 대한 질문)\n",
    "\n",
    "3. 수식을 푸는 문제(여러 공식 formula에 대한 것 : Bias Variance 쪼개지는 것 등)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d75ef5-f11c-47de-a58a-af3bba0771cb",
   "metadata": {},
   "source": [
    "# Resampling(CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53822aaf-f4e9-4036-a3c7-da654aede442",
   "metadata": {},
   "source": [
    "데이터 사이즈가 크기 때문에 요즘은 안쓰기도 함. (Validation만 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832607a-7399-4993-962b-62ea0008c877",
   "metadata": {},
   "source": [
    "## 1. 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702328a-d7ef-4427-a037-4988f671b57c",
   "metadata": {},
   "source": [
    "### **A. Train set / Test set**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57129dc-c8b5-4757-8254-945f6bde1fc1",
   "metadata": {},
   "source": [
    "Validation set approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b235e9-3b66-4765-a2a3-6d9cf5a19df5",
   "metadata": {},
   "source": [
    "* 전체 자료를 랜덤하게 두 그룹으로 분할하여 각각 훈련/평가 자료로 사용, 보통 5:5나 7:3정도로 할당\n",
    "\n",
    "> 훈련 데이터에서 테스트를 안해버림. 오버피팅 문제가 생길 수 있기 때문임... 현실적인 prediction의 상황을 고려\n",
    "\n",
    "* 모형의 평가를 평가 데이터에서 계속 하는 것은 좋지 않음. 또한 애초에 평가 데이터를 모르는 경우도 있음. 따라서 훈련 데이터를 쪼개서 검증을 하는 것이 고려됨 : Validation set\n",
    "\n",
    "> 평가 데이터에서 모형이 어떻게 예측을 할 것인지에 대한 추정, 가장 좋다고 판단되는 모형을 찾은 뒤 다시 데이터를 합쳐 평가 데이터에 적용\n",
    "\n",
    "상황에 따라서 평가 데이터와 검증 데이터를 합칠 수도 있다. Validation set임에도 Test set이라고 하기도 함. 스까있는 경우 : 애초에 Validation이 Test에 대한 추정치이기도 하니까...\n",
    "\n",
    "현실에선 훈련과 검증 데이터만 있고, 모델링만 해서 알아서 활용하라는 것도 있음. 이상적인 것은 훈련/검증/평가이긴 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e3b83-ac6c-4e36-a202-02dd7d6c3b7c",
   "metadata": {},
   "source": [
    "5:5는 평가데이터 비중을 맞추기 위해서, 7:3은 모형을 더 잘 훈련시키기 위해서. 3:7처럼 훈련 데이터를 너무 적게 쓰면 제대로 된 평가가 될까에 따른 의심이 들기 때문. 근데 훈련데이터가 충분히 많으면 상관없나?\n",
    "\n",
    "> 아무튼 적어도 절반은 써라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f79427-3b92-4044-a1dc-e67f0827760d",
   "metadata": {},
   "source": [
    "`-` Validation Set의 선정\n",
    "\n",
    "$$\\begin{align} \\{1, 2, 3, 4, 5, 6\\},& ~ \\{7, 8, 9, 10\\}\\\\\n",
    "\\{1, 2, 4, 7, 8, 9\\},& ~ \\{3, 5, 6, 10\\}\\\\\n",
    "& \\vdots\\end{align}$$\n",
    "\n",
    "> 랜덤으로 선정하여 굉장히 많은 경우가 존재함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21f1be-2444-4e35-8205-7d055c1cc884",
   "metadata": {},
   "source": [
    "`-` 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b1666-7065-4954-8b5f-0bbca71a320f",
   "metadata": {},
   "source": [
    "* **랜덤하게 자료를 분할**하기 때문에 분할 결과에 따라 추정의 변동성이 클 수 있음\n",
    "* 원 자료의 크기보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대추정될 수 있음(적합이 덜 되니까)\n",
    "* 훈련 데이터를 쪼개 훈련/평가(Validation)로 나누고, 실제 적합에서는 훈련 데이터 전체를 사용함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643a57a-8199-42e4-b45a-f011b7b12b16",
   "metadata": {},
   "source": [
    "### **B. Leave-One-Out Cross-Validation(LOOCV)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd25a0-cbd6-49f4-a656-c3b49aa2c5b7",
   "metadata": {},
   "source": [
    "n-1개의 훈련 데이터와 1개의 평가 데이터(Validation set)로 분할, 총 n개의 모형 구성 후 각 평가 데이터에 대한 오차제곱을 더하여 test error를 추정\n",
    "\n",
    "$$\\begin{align} \\text{MSE}_i & = (y_i - \\hat y_{(i)})^2, ~ \\hat y_{(i)} : i\\text{번째 관측치를 제외하고 적합된 모형에 의한 예측치} \\\\\n",
    "CV_{(n)} & = \\frac1n \\underset{i=1}{\\overset{n}{\\sum}}\\text{MSE}_i = \\frac1n \\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\hat y_{(i)})^2 \\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0770f-3f47-439c-9f2f-5adcc4b0e3fb",
   "metadata": {},
   "source": [
    "`-` 장점 : 모형 적합에 n-1개를 사용하기 때문에 정보량에 손해가 거의 없음 -> test error의 과대추정 염려로부터 자유로움. 자료의 분할에 따른 불확실성이 나타나지 않음(모든 자료가 똑같이 validation set에 한 번씩 포함)\n",
    "\n",
    "`-` 단점 : 선형회귀분석을 제외하고 산출하는 데에 계산량이 매우 많아 자료의 크기가 매우 크거나 적합모형의 계산에 시간이 많이 소요되는 경우 적용하기 어려움, 하나의 데이터에서만 예측을 하면(테스트 데이터가 극단적으로 작을 경우) 분산이 커질 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb9651-b32c-46c2-b01b-38163f6057ff",
   "metadata": {},
   "source": [
    "* 다항회귀모형의 경우 다음과 같은 단순화가 가능함\n",
    "\n",
    "$$CV_{(n)} = \\frac1n\\underset{i=1}{\\overset{n}{\\sum}}\\bigg(\\frac{y_i - \\hat y_i}{1-h_{ii}}\\bigg)^2$$\n",
    "\n",
    "여기서 $h_{ii}$는 hat matrix의 i번째 대각원소.\n",
    "\n",
    "> 막 자세히 알 필요는 없음. 그냥 가능하다고만 알아두면 됨?\n",
    ">\n",
    "> 일반적으로 전체 모형의 train error보다 커지는 경향이 있음.\n",
    "\n",
    "위 식으로 한 번의 모형적합을 통해 CV test error를 얻을 수 있음. 하지만, 사용할 수 있는 범위가 좁기 때문에 사용하기 어려움."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e9de89-986c-48ba-bbed-f351af4c89a1",
   "metadata": {},
   "source": [
    "### **C. k-fold CV**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2edab86-44e9-4199-92e3-760ba908f55b",
   "metadata": {},
   "source": [
    "전체 자료를 $k$개의 집합으로 분할한 후, 그 중 하나의 집합을 평가자료로 설정\n",
    "\n",
    "$i$번째 평가자료를 이용한 test error 추정치를 $\\text{MSE}_i$라고 하면, k-fold에 의한 test error 추정치는 아래와 같다.\n",
    "\n",
    "$$CV_{(k)} = \\underset{i=1}{\\overset{k}{\\sum}}\\text{MSE}_i$$\n",
    "\n",
    "> 이 때, learner 별 공유하는 자료가 존재한다. 집합에 속하는 자료들은 비복원추출으로 선정한다.\n",
    ">\n",
    "> fold가 커질 수록 훈련 데이터가 늘어난다. 이에 따라 예측오차가 줄어든다.\n",
    ">\n",
    "> 너무 큰 fold를 쓰면 validation set이 줄어들면서 분산이 커질 수 있다.\n",
    ">\n",
    "> 통상적으로 k는 5, 10 정도를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240366b6-84aa-4856-a384-8480e9487a81",
   "metadata": {},
   "source": [
    "`-` 장점\n",
    "\n",
    "- k번만 모형 적합을 해도 되어 LOOCV에 비해 계산량이 현저히 감소한다.\n",
    "\n",
    "- LOOCV에 비해 test error의 추정이 오히려 정확한 경우가 종종 발생한다.(훈련 자료의 overlap 경감 효과)\n",
    "\n",
    "> 백만개의 데이터가 있다, LOOCV를 쓰면 전체 데이터를 쓴 것과 하나의 데이터를 뺀 모형의 차이가 그렇게 크지 않다. 이에 따라 훈련의 예측오차(train MSE)와 test error의 추정값이 거의 같아질 수 있다.\n",
    "\n",
    "`-` 단점\n",
    "\n",
    "- k개의 집합으로 분할 시 randomness가 발생한다. 이에 따라 test error 추정 시 변동성이 발생한다. 하지만 Validation set approach(한 번 분할)보다는 훨씬 안정적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486abde-6168-4e7b-bbf1-95d9d3e148ec",
   "metadata": {},
   "source": [
    "`-` CV error는 훈련 데이터가 달라지기 때문에 평균과 분산이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb4be5-6757-4944-ad06-2188eddd9226",
   "metadata": {},
   "source": [
    "### **D. 분류 문제에서의 CV**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa094a5b-2f02-4838-b074-fe8e1b456edd",
   "metadata": {},
   "source": [
    "교차타당검증법 CV test는 자료를 어떻게 분할할 것인가에 대한 문제이므로 평가측도와는 큰 관련이 없음.\n",
    "\n",
    "평가자료에서의 오분류율, 민감도, 특이도, AUC 등을 분류기에 대한 지표로 활용할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ce061-fca7-4a9e-8a58-2169d98c9912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
