{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948c238e-b2fa-4a7d-a6b3-0e296077aa52",
   "metadata": {},
   "source": [
    "**시험문제**\n",
    "\n",
    "코드는 거의 안나올거\n",
    "\n",
    "\n",
    "1. OX(거의 나오지 않을 것 같음)\n",
    "\n",
    "2. 간단한 단답형(개념에 대한 질문)\n",
    "\n",
    "3. 수식을 푸는 문제(여러 공식 formula에 대한 것 : Bias Variance 쪼개지는 것 등)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d75ef5-f11c-47de-a58a-af3bba0771cb",
   "metadata": {},
   "source": [
    "# Resampling(CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53822aaf-f4e9-4036-a3c7-da654aede442",
   "metadata": {},
   "source": [
    "데이터 사이즈가 크기 때문에 요즘은 안쓰기도 함. (Validation만 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832607a-7399-4993-962b-62ea0008c877",
   "metadata": {},
   "source": [
    "## 1. 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702328a-d7ef-4427-a037-4988f671b57c",
   "metadata": {},
   "source": [
    "### A. Train set / Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b235e9-3b66-4765-a2a3-6d9cf5a19df5",
   "metadata": {},
   "source": [
    "* 전체 자료를 랜덤하게 두 그룹으로 분할하여 각각 훈련/평가 자료로 사용, 보통 5:5나 7:3정도로 할당\n",
    "\n",
    "> 훈련 데이터에서 테스트를 안해버림. 오버피팅 문제가 생길 수 있기 때문임... 현실적인 prediction의 상황을 고려\n",
    "\n",
    "* 모형의 평가를 평가 데이터에서 계속 하는 것은 좋지 않음. 또한 애초에 평가 데이터를 모르는 경우도 있음. 따라서 훈련 데이터를 쪼개서 검증을 하는 것이 고려됨 : Validation set\n",
    "\n",
    "> 평가 데이터에서 모형이 어떻게 예측을 할 것인지에 대한 추정, 가장 좋다고 판단되는 모형을 찾은 뒤 다시 데이터를 합쳐 평가 데이터에 적용\n",
    "\n",
    "상황에 따라서 평가 데이터와 검증 데이터를 합칠 수도 있다. Validation set임에도 Test set이라고 하기도 함. 스까있는 경우 : 애초에 Validation이 Test에 대한 추정치이기도 하니까...\n",
    "\n",
    "현실에선 훈련과 검증 데이터만 있고, 모델링만 해서 알아서 활용하라는 것도 있음. 이상적인 것은 훈련/검증/평가이긴 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e3b83-ac6c-4e36-a202-02dd7d6c3b7c",
   "metadata": {},
   "source": [
    "5:5는 평가데이터 비중을 맞추기 위해서, 7:3은 모형을 더 잘 훈련시키기 위해서. 3:7처럼 훈련 데이터를 너무 적게 쓰면 제대로 된 평가가 될까에 따른 의심이 들기 때문. 근데 훈련데이터가 충분히 많으면 상관없나?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21f1be-2444-4e35-8205-7d055c1cc884",
   "metadata": {},
   "source": [
    "`-` 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b1666-7065-4954-8b5f-0bbca71a320f",
   "metadata": {},
   "source": [
    "* **랜덤하게 자료를 분할**하기 때문에 분할 결과에 따라 추정의 변동성이 클 수 있음\n",
    "* 원 자료의 크기보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대추정될 수 있음(적합이 덜 되니까)\n",
    "* 훈련 데이터를 쪼개 훈련/평가(Validation)로 나누고, 실제 적합에서는 훈련 데이터 전체를 사용함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643a57a-8199-42e4-b45a-f011b7b12b16",
   "metadata": {},
   "source": [
    "### B. Leave-One-Out Cross-Validation(LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd25a0-cbd6-49f4-a656-c3b49aa2c5b7",
   "metadata": {},
   "source": [
    "n-1개의 훈련 데이터와 1개의 평가 데이터(Validation set)로 분할, 총 n개의 모형 구성 후 각 평가 데이터에 대한 오차제곱을 더하여 test error를 추정\n",
    "\n",
    "$$\\text{MSE}_i = (y_i - \\hat y_{(i)})^2$$\n",
    "\n",
    "$$CV_{(n)} = \\frac$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0770f-3f47-439c-9f2f-5adcc4b0e3fb",
   "metadata": {},
   "source": [
    "장점 : 모형 적합에 n-1개를 사용하기 때문에 정보량에 손해가 거의 없음 -> test error의 과대추정 염려로부터 자유로음\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
