{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948c238e-b2fa-4a7d-a6b3-0e296077aa52",
   "metadata": {},
   "source": [
    "**시험문제**\n",
    "\n",
    "코드는 거의 안나올거\n",
    "\n",
    "\n",
    "1. OX(거의 나오지 않을 것 같음)\n",
    "\n",
    "2. 간단한 단답형(개념에 대한 질문)\n",
    "\n",
    "3. 수식을 푸는 문제(여러 공식 formula에 대한 것 : Bias Variance 쪼개지는 것 등)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d75ef5-f11c-47de-a58a-af3bba0771cb",
   "metadata": {},
   "source": [
    "# Resampling(CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53822aaf-f4e9-4036-a3c7-da654aede442",
   "metadata": {},
   "source": [
    "데이터 사이즈가 크기 때문에 요즘은 안쓰기도 함. (Validation만 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832607a-7399-4993-962b-62ea0008c877",
   "metadata": {},
   "source": [
    "## 1. 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702328a-d7ef-4427-a037-4988f671b57c",
   "metadata": {},
   "source": [
    "### **A. Train set / Test set**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57129dc-c8b5-4757-8254-945f6bde1fc1",
   "metadata": {},
   "source": [
    "**Validation set approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b235e9-3b66-4765-a2a3-6d9cf5a19df5",
   "metadata": {},
   "source": [
    "* 전체 자료를 랜덤하게 두 그룹으로 분할하여 각각 훈련/평가 자료로 사용, 보통 5:5나 7:3정도로 할당\n",
    "\n",
    "> 훈련 데이터에서 테스트를 안해버림. 오버피팅 문제가 생길 수 있기 때문임... 현실적인 prediction의 상황을 고려\n",
    "\n",
    "* 모형의 평가를 평가 데이터에서 계속 하는 것은 좋지 않음. 또한 애초에 평가 데이터를 모르는 경우도 있음. 따라서 훈련 데이터를 쪼개서 검증을 하는 것이 고려됨 : Validation set\n",
    "\n",
    "> 평가 데이터에서 모형이 어떻게 예측을 할 것인지에 대한 추정, 가장 좋다고 판단되는 모형을 찾은 뒤 다시 데이터를 합쳐 평가 데이터에 적용\n",
    "\n",
    "상황에 따라서 평가 데이터와 검증 데이터를 합칠 수도 있다. Validation set임에도 Test set이라고 하기도 함. 스까있는 경우 : 애초에 Validation이 Test에 대한 추정치이기도 하니까...\n",
    "\n",
    "현실에선 훈련과 검증 데이터만 있고, 모델링만 해서 알아서 활용하라는 것도 있음. 이상적인 것은 훈련/검증/평가이긴 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e3b83-ac6c-4e36-a202-02dd7d6c3b7c",
   "metadata": {},
   "source": [
    "5:5는 평가데이터 비중을 맞추기 위해서, 7:3은 모형을 더 잘 훈련시키기 위해서. 3:7처럼 훈련 데이터를 너무 적게 쓰면 제대로 된 평가가 될까에 따른 의심이 들기 때문. 근데 훈련데이터가 충분히 많으면 상관없나?\n",
    "\n",
    "> 아무튼 적어도 절반은 써라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f79427-3b92-4044-a1dc-e67f0827760d",
   "metadata": {},
   "source": [
    "`-` Validation Set의 선정\n",
    "\n",
    "$$\\begin{align} \\{1, 2, 3, 4, 5, 6\\},& ~ \\{7, 8, 9, 10\\}\\\\\n",
    "\\{1, 2, 4, 7, 8, 9\\},& ~ \\{3, 5, 6, 10\\}\\\\\n",
    "& \\vdots\\end{align}$$\n",
    "\n",
    "> 랜덤으로 선정하여 굉장히 많은 경우가 존재함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21f1be-2444-4e35-8205-7d055c1cc884",
   "metadata": {},
   "source": [
    "`-` 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b1666-7065-4954-8b5f-0bbca71a320f",
   "metadata": {},
   "source": [
    "* **랜덤하게 자료를 분할**하기 때문에 분할 결과에 따라 추정의 변동성이 클 수 있음\n",
    "* 원 자료의 크기보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대추정될 수 있음(적합이 덜 되니까)\n",
    "* 훈련 데이터를 쪼개 훈련/평가(Validation)로 나누고, 실제 적합에서는 훈련 데이터 전체를 사용함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643a57a-8199-42e4-b45a-f011b7b12b16",
   "metadata": {},
   "source": [
    "### **B. Leave-One-Out Cross-Validation(LOOCV)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd25a0-cbd6-49f4-a656-c3b49aa2c5b7",
   "metadata": {},
   "source": [
    "n-1개의 훈련 데이터와 1개의 평가 데이터(Validation set)로 분할, 총 n개의 모형 구성 후 각 평가 데이터에 대한 오차제곱을 더하여 test error를 추정\n",
    "\n",
    "$$\\begin{align} \\text{MSE}_i & = (y_i - \\hat y_{(i)})^2, ~ \\hat y_{(i)} : i\\text{번째 관측치를 제외하고 적합된 모형에 의한 예측치} \\\\\n",
    "CV_{(n)} & = \\frac1n \\underset{i=1}{\\overset{n}{\\sum}}\\text{MSE}_i = \\frac1n \\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\hat y_{(i)})^2 \\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0770f-3f47-439c-9f2f-5adcc4b0e3fb",
   "metadata": {},
   "source": [
    "`-` 장점 : 모형 적합에 n-1개를 사용하기 때문에 정보량에 손해가 거의 없음 -> test error의 과대추정 염려로부터 자유로움. 자료의 분할에 따른 불확실성이 나타나지 않음(모든 자료가 똑같이 validation set에 한 번씩 포함)\n",
    "\n",
    "`-` 단점 : 선형회귀분석을 제외하고 산출하는 데에 계산량이 매우 많아 자료의 크기가 매우 크거나 적합모형의 계산에 시간이 많이 소요되는 경우 적용하기 어려움, 하나의 데이터에서만 예측을 하면(테스트 데이터가 극단적으로 작을 경우) 분산이 커질 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb9651-b32c-46c2-b01b-38163f6057ff",
   "metadata": {},
   "source": [
    "* 다항회귀모형의 경우 다음과 같은 단순화가 가능함\n",
    "\n",
    "$$CV_{(n)} = \\frac1n\\underset{i=1}{\\overset{n}{\\sum}}\\bigg(\\frac{y_i - \\hat y_i}{1-h_{ii}}\\bigg)^2$$\n",
    "\n",
    "여기서 $h_{ii}$는 hat matrix의 i번째 대각원소.\n",
    "\n",
    "> 막 자세히 알 필요는 없음. 그냥 가능하다고만 알아두면 됨?\n",
    ">\n",
    "> 일반적으로 전체 모형의 train error보다 커지는 경향이 있음.\n",
    "\n",
    "위 식으로 한 번의 모형적합을 통해 CV test error를 얻을 수 있음. 하지만, 사용할 수 있는 범위가 좁기 때문에 사용하기 어려움."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e9de89-986c-48ba-bbed-f351af4c89a1",
   "metadata": {},
   "source": [
    "### **C. k-fold CV**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2edab86-44e9-4199-92e3-760ba908f55b",
   "metadata": {},
   "source": [
    "전체 자료를 $k$개의 집합으로 분할한 후, 그 중 하나의 집합을 평가자료로 설정\n",
    "\n",
    "$i$번째 평가자료를 이용한 test error 추정치를 $\\text{MSE}_i$라고 하면, k-fold에 의한 test error 추정치는 아래와 같다.\n",
    "\n",
    "$$CV_{(k)} = \\frac1k\\underset{i=1}{\\overset{k}{\\sum}}\\text{MSE}_i$$\n",
    "\n",
    "> 이 때, learner 별 공유하는 자료가 존재한다. 집합에 속하는 자료들은 비복원추출으로 선정한다.\n",
    ">\n",
    "> fold가 커질 수록 훈련 데이터가 늘어난다. 이에 따라 예측오차가 줄어든다.\n",
    ">\n",
    "> 너무 큰 fold를 쓰면 validation set이 줄어들면서 분산이 커질 수 있다.\n",
    ">\n",
    "> 통상적으로 k는 5, 10 정도를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240366b6-84aa-4856-a384-8480e9487a81",
   "metadata": {},
   "source": [
    "`-` 장점\n",
    "\n",
    "- k번만 모형 적합을 해도 되어 LOOCV에 비해 계산량이 현저히 감소한다.\n",
    "\n",
    "- LOOCV에 비해 test error의 추정이 오히려 정확한 경우가 종종 발생한다.(훈련 자료의 overlap 경감 효과)\n",
    "\n",
    "> 백만개의 데이터가 있다, LOOCV를 쓰면 전체 데이터를 쓴 것과 하나의 데이터를 뺀 모형의 차이가 그렇게 크지 않다. 이에 따라 훈련의 예측오차(train MSE)와 test error의 추정값이 거의 같아질 수 있다.\n",
    "\n",
    "`-` 단점\n",
    "\n",
    "- k개의 집합으로 분할 시 randomness가 발생한다. 이에 따라 test error 추정 시 변동성이 발생한다. 하지만 Validation set approach(한 번 분할)보다는 훨씬 안정적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486abde-6168-4e7b-bbf1-95d9d3e148ec",
   "metadata": {},
   "source": [
    "`-` CV error는 훈련 데이터가 달라지기 때문에 평균과 분산이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb4be5-6757-4944-ad06-2188eddd9226",
   "metadata": {},
   "source": [
    "### **D. 분류 문제에서의 CV**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa094a5b-2f02-4838-b074-fe8e1b456edd",
   "metadata": {},
   "source": [
    "교차타당검증법 CV test는 자료를 어떻게 분할할 것인가에 대한 문제이므로 평가측도와는 큰 관련이 없음.\n",
    "\n",
    "평가자료에서의 오분류율, 민감도, 특이도, AUC 등을 분류기에 대한 지표로 활용할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b10cfe-d9e9-4cfd-a097-94a0280d44c9",
   "metadata": {},
   "source": [
    "> 분류문제에서의 LOOCV에 의한 오분류율\n",
    "\n",
    "$$CV_{(n)} = \\frac1n\\sum I(y_i \\neq \\hat y_{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fa36d-4217-4f5e-9d00-25342a79be0f",
   "metadata": {},
   "source": [
    "### **E. Test error의 minimizer**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7a5e1-7405-47e0-b1d6-3c7a824ea3f3",
   "metadata": {},
   "source": [
    "test error의 추정 자체에 관심이 있는 경우, 언제 test error가 최소가 되는지에 관심이 있는 경우.\n",
    "\n",
    "후자의 경우 test error의 과대/과소 추정에는 보다 관대할 수 있음.\n",
    "\n",
    "true test MSE와, LOOCV estimate와, 10-fold estimate에 대해서 최소화하는 것이 test MSE를 최소화하는 점과 동일하지 않을 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1542c6-068b-46dc-a445-807c8325d2b0",
   "metadata": {},
   "source": [
    "k-fold CV : k = 5일 때, 각각 오차제곱합이 나오고, 이들의 평균과 표준오차를 구할 수 있음. MSE CURVE가 있을 때, 최소점에 대한 표준오차 바운더리가 나오고, 그 구간 내의 점 중에서 가장 간단한 모형을 택하는 경우가 많음.\n",
    "\n",
    "> 최대한 Simple한 모형으로 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ba0e5-8340-465a-ae19-6f594b5cc674",
   "metadata": {},
   "source": [
    "### **F. Bootstrap**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044b610-1d29-4b1e-9b88-4413e0750a0f",
   "metadata": {},
   "source": [
    "`-` 주어진 데이터의 크기가 n일 때, 각각의 데이터 포인트에 대해서 1/n의 확률을 주고 복원추출함.\n",
    "\n",
    "`-` 주로 추정량의 분산을 정확히 알기 어려울 때, 이를 알아내는 방법으로 사용함.\n",
    "\n",
    "$$\\begin{align} \\hat\\theta_1 : Y_{11}, Y_{12}, \\cdots, Y_{1n} \\sim F \\\\\n",
    "\\hat\\theta_2 : Y_{21}, Y_{22}, \\cdots, Y_{2n} \\sim F \\\\ \\\\ \n",
    "Y_1, Y_2, \\cdots, Y_n \\sim F_n \\\\\n",
    "Y_{11}', Y_{12}', \\cdots, Y_{1n}' \\to \\hat \\theta^{(1)} \\\\\n",
    "Y_{21}', Y_{22}', \\cdots, Y_{2n}' \\to \\hat \\theta^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "Y_{b1}', Y_{b2}', \\cdots, Y_{bn}' \\to \\hat \\theta^{(b)}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b9615-13c5-4469-ac6e-1117e046fbe1",
   "metadata": {},
   "source": [
    "관측된 표본을 모집단으로 하는 분포에서 새로운 subsample을 만들어내는 것.\n",
    "\n",
    "표본을 sampling하여 산출된 분산이 실제 F의 분산에 수렴한다는 것이 알려져 있다.\n",
    "\n",
    "> 원래 해야 되는 것은 F인데, 실제로 할 수 없으니까 sample에서 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df8024-83d4-468b-8b91-a2320e201d0f",
   "metadata": {},
   "source": [
    "## 2. 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7b400-ac85-466c-8d35-2d2e630b573b",
   "metadata": {},
   "source": [
    "**cross validation 코드를 주로 이해하면 됨. 그러면 이 장에서 할 수 있는 걸 완벽하게 이해한 거라고 보면 됨 ㅇㅇ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a3ae83-c69b-4d16-9d37-81f62fe18ca2",
   "metadata": {},
   "source": [
    "### Extraction of Main code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e9e33-861e-4aa4-ad1e-a49d65792d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation set approach\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2) ## validation mse(test mse 추정치)\n",
    "\n",
    "## Cross validation\n",
    "sklearn.model_selection.train_test_split(df, test_size = \"float or int\", random_state = \"seed\")\n",
    "sklearn.model_selection.KFold(n_splits=\"int\", shuffle=\"bool\", random_state=\"seed\") ## shuffle = True로 randomness 확보\n",
    "sklearn.model_selection.cross_validate(predictr, X, Y, cv=\"int or KFold object\")\n",
    "\n",
    "## Bootstrap\n",
    "indx = np.random.default_rng().choice(n, n, replace = True) ## 복원추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fe8de-f86e-4cd5-8dbc-897f54057f23",
   "metadata": {},
   "source": [
    "### **A. 라이브러리 imports**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af574c1e-93d8-4481-b314-ff8f577c6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS, summarize, poly)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.model_selection import (cross_validate , KFold , ShuffleSplit) ## CV random split\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671dd0bc-49b8-4ed5-a11a-680efe1cbe26",
   "metadata": {},
   "source": [
    "### **B. 데이터**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349c2f00-864c-4aac-b0da-ff22e002d871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.599\n",
      "Model:                            OLS   Adj. R-squared:                  0.598\n",
      "Method:                 Least Squares   F-statistic:                     433.9\n",
      "Date:                Tue, 22 Oct 2024   Prob (F-statistic):           1.48e-59\n",
      "Time:                        09:30:23   Log-Likelihood:                -879.71\n",
      "No. Observations:                 292   AIC:                             1763.\n",
      "Df Residuals:                     290   BIC:                             1771.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept     39.8828      0.848     47.020      0.000      38.213      41.552\n",
      "horsepower    -0.1587      0.008    -20.831      0.000      -0.174      -0.144\n",
      "==============================================================================\n",
      "Omnibus:                        8.415   Durbin-Watson:                   2.042\n",
      "Prob(Omnibus):                  0.015   Jarque-Bera (JB):                8.304\n",
      "Skew:                           0.397   Prob(JB):                       0.0157\n",
      "Kurtosis:                       3.226   Cond. No.                         327.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "24.22829297680054\n",
      "23.201930047104227\n"
     ]
    }
   ],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=100, random_state=0) ## validation을 보고 있음\n",
    "\n",
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "train_pred = results.predict(X_train)\n",
    "\n",
    "print(np.mean((y_train - train_pred)**2)) ## trian mse\n",
    "print(np.mean((y_valid - valid_pred)**2)) ## validation mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ee4d1-6c11-4120-9e4f-31b62d69d260",
   "metadata": {},
   "source": [
    "> train보다 validation의 MSE가 조금 더 작음. 자료의 수가 적으면 이런 상황이 나올 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e50995-9861-4b84-aab2-a583c0b0eb0f",
   "metadata": {},
   "source": [
    "### **C. 훈련 및 검증오차**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d153a422-b22a-4818-a892-fb5aa0570283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련과 검증 오차를 확인하는 함수 생성\n",
    "# -------------------------------------\n",
    "def evalMSE(terms, response , train , test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b576c0a7-6d58-423c-aef0-4b6bee6f933f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.20193005, 16.99348987, 16.9506061 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)], 'mpg', Auto_train, Auto_valid) ## 1~3차 회귀모형\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a58d23-e247-414d-ace4-09cc46aaa696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.23151351792922"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS, MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model, X, Y, cv=Auto.shape[0]) ## 전체 데이터를 넣어주면 알아서 쪼개고 LOOCV\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090173b8-82f5-4874-99f7-b9ccbd75d81e",
   "metadata": {},
   "source": [
    "* 다항식의 차수를 키웠을 때의 교차검증오차(LOOCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c1d6da-79e5-489e-ac0f-f948310db4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443029, 19.03320648])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "\n",
    "for i, d in enumerate(range(1,6)):\n",
    "  X = np.power.outer(H, np.arange(d+1))\n",
    "  M_CV = cross_validate(M, X, Y, cv=Auto.shape[0])\n",
    "  cv_error[i] = np.mean(M_CV['test_score'])\n",
    "\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0efe9f-475f-4210-b79b-d72cd19c0d84",
   "metadata": {},
   "source": [
    "* 셔플을 한 K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b3ba6a-07a7-43a3-8243-ec1db19abd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=40, random_state=0, shuffle=True)\n",
      "[18.93586159 18.93586159 18.93586159 18.93586159 18.93586159]\n"
     ]
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "# 40개로 쪼개는 CV\n",
    "cv = KFold(n_splits=40, shuffle=True, random_state=0) ## shuffle을 꼭 해줘야 함. randomness 확보\n",
    "print(cv)\n",
    "\n",
    "# use same splits for each degree for i, d in enumerate(range(1,6)):\n",
    "X = np.power.outer(H, np.arange(d+1))\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    M_CV = cross_validate(M, X, Y, cv=cv) ## 전체 데이터를 먹이고, cv에 KFold object를 입력\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "print(cv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfafbcc-d19c-466a-bbe8-3dc5ad290f3d",
   "metadata": {},
   "source": [
    "* 두 개로 쪼개서 validation error 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806dd3aa-3cb3-4ee3-a536-2b1b5f945733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.0047152]), 'score_time': array([0.00140858]), 'test_score': array([23.61661707])}\n"
     ]
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1, test_size=196, random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "Auto.drop(['mpg'], axis=1), Auto['mpg'], cv =validation)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ddd1f-ff20-451e-8901-50fc76d56d52",
   "metadata": {},
   "source": [
    "### **D. Bootstrap**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156acb9-f618-400c-a565-1fa6722807a4",
   "metadata": {},
   "source": [
    "-  $Var ( \\alpha X + ( 1- \\alpha)Y)$를 최소화하는 문제: 수식에 의해서 $\\alpha$에 대한 해는\n",
    "$$ \\frac{ \\sigma_Y^2 - \\sigma_{XY} }{  \\sigma_X^2 + \\sigma_Y^2 - 2 \\sigma_{XY} }$$\n",
    "\n",
    "> 분산을 계산하는 게 쉽지 않음. -> bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afd242a8-4c3b-4005-8b13-493c1d41cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 데이터의 인덱싱을 통해서 공분산을 얻고 해를 구함\n",
    "# -------------------------------------------------------\n",
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1,1] - cov_[0,1]) / (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e717d6a5-ad88-43a5-98fa-347ef3640aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위 함수를 구동\n",
    "# --------------\n",
    "rng = np.random.default_rng()\n",
    "idx = rng.choice(100, 100, replace=True)\n",
    "idx = range(Portfolio.shape[0])\n",
    "alpha_func(Portfolio, idx)\n",
    "# index를 랜덤하게 정해서 결과를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89404c44-ec04-4e97-99aa-e02297cecf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08945522198999856"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def boot_SE(func, D, n=None, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_ , second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2) # 표준편차 계산\n",
    "\n",
    "alpha_SE = boot_SE(alpha_func, Portfolio ,B=1000, seed=1)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d3466fd-449e-48cb-afef-e496e760d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "   D_ = D.iloc[idx]     #D.iloc #\n",
    "   Y_ = D_[response]\n",
    "   X_ = clone(model_matrix).fit_transform(D_)\n",
    "   return sm.OLS(Y_, X_).fit().params\n",
    "\n",
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n",
    "# 함수를 구동할 때 모든 인자가 아니라 필요 인지만 받을 수 있게 함\n",
    "# 앞에 두 인자는 고정시키게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42d26b01-f3ce-44db-a55b-3f95d9acf98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39.88064456 -0.1567849 ]\n",
      " [38.73298691 -0.14699495]\n",
      " [38.31734657 -0.14442683]\n",
      " [39.91446826 -0.15782234]\n",
      " [39.43349349 -0.15072702]\n",
      " [40.36629857 -0.15912217]\n",
      " [39.62334517 -0.15449117]\n",
      " [39.0580588  -0.14952908]\n",
      " [38.66688437 -0.14521037]\n",
      " [39.64280792 -0.15555698]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "kk = [hp_func(Auto, rng.choice(392, 392, replace=True)) for _ in range(10)]\n",
    "print(np.array(kk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b51cc3ae-6262-4406-8d15-e2d003fdb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept     0.717654\n",
      "horsepower    0.006041\n",
      "dtype: float64\n",
      "intercept     0.717\n",
      "horsepower    0.006\n",
      "Name: std err, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "   D_ = D.loc[idx]     #D.iloc #\n",
    "   Y_ = D_[response]\n",
    "   X_ = clone(model_matrix).fit_transform(D_)\n",
    "   return sm.OLS(Y_, X_).fit().params\n",
    "\n",
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n",
    "hp_se = boot_SE(hp_func, Auto, B=1000, seed=0)\n",
    "print(hp_se)\n",
    "\n",
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "print(model_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04a05e67-f31c-44df-b277-da3584848ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept                                  1.538641\n",
      "poly(horsepower, degree=2, raw=True)[0]    0.024696\n",
      "poly(horsepower, degree=2, raw=True)[1]    0.000090\n",
      "dtype: float64\n",
      "intercept                                  1.800\n",
      "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
      "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
      "Name: std err, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS, quad_model, 'mpg')\n",
    "print(boot_SE(quad_func, Auto, B=1000))\n",
    "\n",
    "M = sm.OLS(Auto['mpg'], quad_model.fit_transform(Auto))\n",
    "print(summarize(M.fit())['std err'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
