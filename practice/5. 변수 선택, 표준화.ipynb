{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06600d9-7102-4803-a37d-741e54866d61",
   "metadata": {},
   "source": [
    "# Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f65f2b-8b21-4030-be44-f1de079cb26b",
   "metadata": {},
   "source": [
    "## 1. 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af6d35-7c17-43c9-9275-5fe8eedbc658",
   "metadata": {},
   "source": [
    "### **A. Imporving linear models**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5619ae-3843-4679-91c2-e59a8b01cd97",
   "metadata": {},
   "source": [
    "`-` 예측력을 올리고, 설명력을 키우고 싶은데, 변수를 현재 있는 전부를 사용하면 안되는 경우.\n",
    "\n",
    "`-` 반응변수에 별 다른 영향력이 없는 예측변수는 모형의 복잡성만을 초래함. 변수가 고차원인 경우 해석도 어려울 뿐더러 성능의저하도 가져옴."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800bf9a2-8af6-4d65-985b-fdd5a0bbe2b4",
   "metadata": {},
   "source": [
    "`-` 최소제곱추정에 대한 대안 : 크게 세 가지 유형\n",
    "\n",
    "- Subset selection : 전체 예측변수들 중 모형에 포함시킬 일부만 식별\n",
    "\n",
    "- Shrinkage(축소) 방법 : p개의 예측변수를 모두 포함하여 자료를 적합하되, 추정된 계수들에는 0을 향한 축소가 일어남. 이러한 축소는 추정량의 분산을 감소시키는 효과가 있음 : Ridge, Lasso\n",
    "\n",
    "- Dimension reduction : p개의 예측변수로 이루어진 공간을 M차원의 부분공간으로 정사영한 후 모형 적합 : PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8662d2-2920-4c68-b757-cbf2e3eef595",
   "metadata": {},
   "source": [
    "### **B. Best subset selection**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124178f-864c-421c-89c2-45b55ae95d6a",
   "metadata": {},
   "source": [
    "`-` k개의 예측변수를 포함하는 모형을 모두 적합하여 적절한 기준으로 가장 좋은 모형을 선택\n",
    "\n",
    "> $C_p, AIC, BIC, \\text{adjusted}-R^2$등을 이용하여 가장 우수한 모형 선택\n",
    ">\n",
    "> p가 커짐에 따라 계산량이 지수적으로 증가하는 단점이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02e34e-d294-4649-931a-234c6e099b83",
   "metadata": {},
   "source": [
    "$k = 0, 1, \\cdots, p$에 대하여 위 과정을 반복하여 $M_0, \\cdots, M_p$ 생성, 이 모형 중 가장 우수한 모형 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532d27e-2a63-470c-8b7f-2a78e438da32",
   "metadata": {},
   "source": [
    "`-` 전진선택법\n",
    "\n",
    "1. 예측변수가 없는 모형 $M_0$에서 출발\n",
    "2. $k = 0, \\cdots, p-1$에 대하여 다음을 실행\n",
    "\n",
    "* $M_k$에서 하나의 변수가 추가된 $p-k$개의 모형을 고려\n",
    "* 적절한 기준에서 가장 우수한 모형 $M_{k+1}$ 선택\n",
    "\n",
    "3. 기준치에 대하여 $M_0, \\cdots, M_p$ 중 가장 우수한 모형 선택\n",
    "\n",
    "> 새로운 변수를 추가했을 때, 기준치가 개선되지 않았다면 변수 추가를 멈춤. 이에 따라 계산이 가장 빠르다.\n",
    "\n",
    "2번 과정의 기준과, 3번 과정의 기준을 다르게 설정하는 것도 가능함. 가능하면 일치시키는 게 좋음. 계산량은 경감되나 best model을 선택할 수 있다는 보장은 없음.(다중공선성을 고려하지 않음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1b103-3a55-4577-a7b4-1ceb85667eb6",
   "metadata": {},
   "source": [
    "`-` 후진제거법\n",
    "\n",
    "1. 예측변수가 모두 포함된 모형 $M_p$에서 출발\n",
    "2. $k = p, p-1, \\cdots, 1$에 대하여 다음을 실행\n",
    "* $M_k$에서 하나의 변수만을 제외한 $k$개의 모형을 각각 고려\n",
    "* $RSS$ 또는 $R^2$의 관점에서 가장 우수한 모형 $M_{k-1}$ 선택\n",
    "\n",
    "3. 기준치에 대하여 가장 우수한 모형 선택\n",
    "\n",
    "> 전진선택법보다 계산량이 일반적으로 많음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bd142-9ea7-489b-a3f5-0fc715cadcc2",
   "metadata": {},
   "source": [
    "`-` Hybrid approaches\n",
    "\n",
    "* 다중공선성의 문제 때문에 전진선택법과 후진제거법을 혼합. forward의 방식을 기본적으로 따르되, 새로운 변수가 하나 추가된 후 모형적합에 더이상 도움이 되지 않아 제거가 필요한 변수가 있는지 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86760281-c840-47cc-a568-8914c2b10ea0",
   "metadata": {},
   "source": [
    "### **C. 평가 측도**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63359b63-883d-4628-a7ab-84d1005f0550",
   "metadata": {},
   "source": [
    "`-` 최적모형 선택을 위해선 test error에 대한 추정이 필요함.\n",
    "\n",
    "* 교차타당검증(CV)을 이용하여 직접적으로 test error를 추정\n",
    "* training error에 과적합 등에 따른 편의를 고려한 보정을 가하는 방식으로 간접적으로 test error를 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3075f2c-f675-46ab-9c96-b99767450449",
   "metadata": {},
   "source": [
    "`-` 평가 측도 : training error 보정\n",
    "\n",
    "* $RSS, R^2$ 등은 모형의 복잡도에 따라 단조적으로 변하는 측도이므로 최적모형 선택에 도움이 되지 않음.\n",
    "* training error를 모형의 크기(복잡도 또는 모수의 개수)에 대하여 보정한 측도들 활용\n",
    "* $C_p, AIC, BIC, \\text{adjusted}-R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a07aca-4a79-476e-bc03-c086b5195ef7",
   "metadata": {},
   "source": [
    "`-` $C_p$\n",
    "\n",
    "* p개의 예측변수를 포함한 모형에서 test MSE에 대한 추정량\n",
    "\n",
    "$$C_p = \\frac1n(RSS + 2p\\hat \\sigma^2)$$\n",
    "\n",
    "> $E[(y' - x^{\\top}\\hat \\beta)^2] - E[(y - x^{\\top}\\hat \\beta)^2] = 2p \\hat \\sigma^2$이며, $y'$는 평가데이터에서, $y$는 훈련데이터에서 나옴. $\\hat \\sigma^2$은 오차항의 분산 추정치임.\n",
    ">\n",
    "> 원래는 $\\sigma$를 넣어야 하는데, $\\hat \\sigma^2$를 넣음. 추정량이므로 바뀌지 않는 고정된 값임\n",
    ">\n",
    "> 원래 있던 강의록의 내용과 다름. 이 쪽이 더 엄밀한 정의임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2c5a4-a5f5-4b40-a8ac-2278f66feabd",
   "metadata": {},
   "source": [
    "`-` AIC(Akaike Information Criterion)\n",
    "\n",
    "$$AIC = -2 \\log \\hat L + 2p ∝ n \\log \\hat \\sigma^2 + 2p$$\n",
    "\n",
    "> $C_p$와 달리 원래 $\\hat \\sigma^2$를 사용함. 여기서는 모형마다의 추정치, MSE를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34747604-46f0-4b77-829a-5f1394f9bb6e",
   "metadata": {},
   "source": [
    "`-` BIC(Bayesian Information Criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718a3a9-847e-4b15-acf4-9c253038374c",
   "metadata": {},
   "source": [
    "$$BIC = -2 \\log \\hat L + (\\log n) p ∝ n \\log \\hat \\sigma^2 + (\\log n)p$$\n",
    "\n",
    "> $n > 7$면 $\\log(n) > 2$이므로, AIC보다 상대적으로 단순한 모형을 선택하도록 만듦."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a207545-ce5e-405d-979e-5ed1abda1955",
   "metadata": {},
   "source": [
    "`-` $\\text{Adjusted}-R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d2415-02b7-4d86-8ebb-2a640b887a6a",
   "metadata": {},
   "source": [
    "$$\\text{Adjusted}-R^2 = 1 - \\frac{RSS/(n-p-1)}{TSS/(n-1)}$$\n",
    "\n",
    "> 변수의 개수가 늘어날 때, 값이 무지성으로 늘어나지 않음.\n",
    ">\n",
    "> 해당 값을 최대화하는 것은 $RSS/(n-p-1)$을 최소화시키는 것과 동치.\n",
    ">\n",
    "> 이해가 쉬운 반면, 이론적인 배경은 빈약함. 이론적인 정당성은 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a20d6-b7a2-44a4-9423-bdc24fc779e4",
   "metadata": {},
   "source": [
    "`-` $C_p, AIC, BIC$ 측도들은 선형모형 뿐 아니라 좀 더 일반적인 형태의 모형 하에서도 적절히 정의될 수 이씅며, 모형 선택에 활용될 수 있음.\n",
    "\n",
    "`-` 과거에는 보정측도들을 널리 사용하였으나, 계산능력의 향상으로 교차타당검증법(CV)도 매우 대중적으로 변함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4c070-86f1-4774-915b-570ba65efff7",
   "metadata": {},
   "source": [
    "### **D. One-standard-error rule**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeadf2ca-6f8c-48d4-87fb-74654d022d39",
   "metadata": {},
   "source": [
    "교차타당검증에는 데이터셋 분할에 따른 변동성이 존재할 수 있음 : CV에서 MSE의 표준오차$e$ 추정. 최적으로 판명된 모형의 test MSE에서 $e$이내의 test MSE를 가지는 모형들은 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6c485-5248-444b-8bb6-e65af40ecd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anova t검정 안하면 감점?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
