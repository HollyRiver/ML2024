{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06600d9-7102-4803-a37d-741e54866d61",
   "metadata": {},
   "source": [
    "# Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f65f2b-8b21-4030-be44-f1de079cb26b",
   "metadata": {},
   "source": [
    "## 1. 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af6d35-7c17-43c9-9275-5fe8eedbc658",
   "metadata": {},
   "source": [
    "### **A. Imporving linear models**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5619ae-3843-4679-91c2-e59a8b01cd97",
   "metadata": {},
   "source": [
    "`-` 예측력을 올리고, 설명력을 키우고 싶은데, 변수를 현재 있는 전부를 사용하면 안되는 경우.\n",
    "\n",
    "`-` 반응변수에 별 다른 영향력이 없는 예측변수는 모형의 복잡성만을 초래함. 변수가 고차원인 경우 해석도 어려울 뿐더러 성능의저하도 가져옴."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800bf9a2-8af6-4d65-985b-fdd5a0bbe2b4",
   "metadata": {},
   "source": [
    "`-` 최소제곱추정에 대한 대안 : 크게 세 가지 유형\n",
    "\n",
    "- Subset selection : 전체 예측변수들 중 모형에 포함시킬 일부만 식별\n",
    "\n",
    "- Shrinkage(축소) 방법 : p개의 예측변수를 모두 포함하여 자료를 적합하되, 추정된 계수들에는 0을 향한 축소가 일어남. 이러한 축소는 추정량의 분산을 감소시키는 효과가 있음 : Ridge, Lasso\n",
    "\n",
    "- Dimension reduction : p개의 예측변수로 이루어진 공간을 M차원의 부분공간으로 정사영한 후 모형 적합 : PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8662d2-2920-4c68-b757-cbf2e3eef595",
   "metadata": {},
   "source": [
    "### **B. Best subset selection**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124178f-864c-421c-89c2-45b55ae95d6a",
   "metadata": {},
   "source": [
    "`-` k개의 예측변수를 포함하는 모형을 모두 적합하여 적절한 기준으로 가장 좋은 모형을 선택\n",
    "\n",
    "> $C_p, AIC, BIC, \\text{adjusted}-R^2$등을 이용하여 가장 우수한 모형 선택\n",
    ">\n",
    "> p가 커짐에 따라 계산량이 지수적으로 증가하는 단점이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02e34e-d294-4649-931a-234c6e099b83",
   "metadata": {},
   "source": [
    "$k = 0, 1, \\cdots, p$에 대하여 위 과정을 반복하여 $M_0, \\cdots, M_p$ 생성, 이 모형 중 가장 우수한 모형 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532d27e-2a63-470c-8b7f-2a78e438da32",
   "metadata": {},
   "source": [
    "`-` 전진선택법\n",
    "\n",
    "1. 예측변수가 없는 모형 $M_0$에서 출발\n",
    "2. $k = 0, \\cdots, p-1$에 대하여 다음을 실행\n",
    "\n",
    "* $M_k$에서 하나의 변수가 추가된 $p-k$개의 모형을 고려\n",
    "* 적절한 기준에서 가장 우수한 모형 $M_{k+1}$ 선택\n",
    "\n",
    "3. 기준치에 대하여 $M_0, \\cdots, M_p$ 중 가장 우수한 모형 선택\n",
    "\n",
    "> 새로운 변수를 추가했을 때, 기준치가 개선되지 않았다면 변수 추가를 멈춤. 이에 따라 계산이 가장 빠르다.\n",
    "\n",
    "2번 과정의 기준과, 3번 과정의 기준을 다르게 설정하는 것도 가능함. 가능하면 일치시키는 게 좋음. 계산량은 경감되나 best model을 선택할 수 있다는 보장은 없음.(다중공선성을 고려하지 않음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1b103-3a55-4577-a7b4-1ceb85667eb6",
   "metadata": {},
   "source": [
    "`-` 후진제거법\n",
    "\n",
    "1. 예측변수가 모두 포함된 모형 $M_p$에서 출발\n",
    "2. $k = p, p-1, \\cdots, 1$에 대하여 다음을 실행\n",
    "* $M_k$에서 하나의 변수만을 제외한 $k$개의 모형을 각각 고려\n",
    "* $RSS$ 또는 $R^2$의 관점에서 가장 우수한 모형 $M_{k-1}$ 선택\n",
    "\n",
    "3. 기준치에 대하여 가장 우수한 모형 선택\n",
    "\n",
    "> 전진선택법보다 계산량이 일반적으로 많음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bd142-9ea7-489b-a3f5-0fc715cadcc2",
   "metadata": {},
   "source": [
    "`-` Hybrid approaches\n",
    "\n",
    "* 다중공선성의 문제 때문에 전진선택법과 후진제거법을 혼합. forward의 방식을 기본적으로 따르되, 새로운 변수가 하나 추가된 후 모형적합에 더이상 도움이 되지 않아 제거가 필요한 변수가 있는지 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86760281-c840-47cc-a568-8914c2b10ea0",
   "metadata": {},
   "source": [
    "### **C. 평가 측도**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63359b63-883d-4628-a7ab-84d1005f0550",
   "metadata": {},
   "source": [
    "`-` 최적모형 선택을 위해선 test error에 대한 추정이 필요함.\n",
    "\n",
    "* 교차타당검증(CV)을 이용하여 직접적으로 test error를 추정\n",
    "* training error에 과적합 등에 따른 편의를 고려한 보정을 가하는 방식으로 간접적으로 test error를 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3075f2c-f675-46ab-9c96-b99767450449",
   "metadata": {},
   "source": [
    "`-` 평가 측도 : training error 보정\n",
    "\n",
    "* $RSS, R^2$ 등은 모형의 복잡도에 따라 단조적으로 변하는 측도이므로 최적모형 선택에 도움이 되지 않음.\n",
    "* training error를 모형의 크기(복잡도 또는 모수의 개수)에 대하여 보정한 측도들 활용\n",
    "* $C_p, AIC, BIC, \\text{adjusted}-R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a07aca-4a79-476e-bc03-c086b5195ef7",
   "metadata": {},
   "source": [
    "`-` $C_p$\n",
    "\n",
    "* p개의 예측변수를 포함한 모형에서 test MSE에 대한 추정량\n",
    "\n",
    "$$C_p = \\frac1n(RSS + 2p\\hat \\sigma^2)$$\n",
    "\n",
    "> $E[(y' - x^{\\top}\\hat \\beta)^2] - E[(y - x^{\\top}\\hat \\beta)^2] = 2p \\hat \\sigma^2$이며, $y'$는 평가데이터에서, $y$는 훈련데이터에서 나옴. $\\hat \\sigma^2$은 오차항의 분산 추정치임.\n",
    ">\n",
    "> 원래는 $\\sigma$를 넣어야 하는데, $\\hat \\sigma^2$를 넣음. 추정량이므로 바뀌지 않는 고정된 값임\n",
    ">\n",
    "> 원래 있던 강의록의 내용과 다름. 이 쪽이 더 엄밀한 정의임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2c5a4-a5f5-4b40-a8ac-2278f66feabd",
   "metadata": {},
   "source": [
    "`-` AIC(Akaike Information Criterion)\n",
    "\n",
    "$$AIC = -2 \\log \\hat L + 2p ∝ n \\log \\hat \\sigma^2 + 2p$$\n",
    "\n",
    "> $C_p$와 달리 원래 $\\hat \\sigma^2$를 사용함. 여기서는 모형마다의 추정치, MSE를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34747604-46f0-4b77-829a-5f1394f9bb6e",
   "metadata": {},
   "source": [
    "`-` BIC(Bayesian Information Criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718a3a9-847e-4b15-acf4-9c253038374c",
   "metadata": {},
   "source": [
    "$$BIC = -2 \\log \\hat L + (\\log n) p ∝ n \\log \\hat \\sigma^2 + (\\log n)p$$\n",
    "\n",
    "> $n > 7$면 $\\log(n) > 2$이므로, AIC보다 상대적으로 단순한 모형을 선택하도록 만듦."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a207545-ce5e-405d-979e-5ed1abda1955",
   "metadata": {},
   "source": [
    "`-` $\\text{Adjusted}-R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d2415-02b7-4d86-8ebb-2a640b887a6a",
   "metadata": {},
   "source": [
    "$$\\text{Adjusted}-R^2 = 1 - \\frac{RSS/(n-p-1)}{TSS/(n-1)}$$\n",
    "\n",
    "> 변수의 개수가 늘어날 때, 값이 무지성으로 늘어나지 않음.\n",
    ">\n",
    "> 해당 값을 최대화하는 것은 $RSS/(n-p-1)$을 최소화시키는 것과 동치.\n",
    ">\n",
    "> 이해가 쉬운 반면, 이론적인 배경은 빈약함. 이론적인 정당성은 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a20d6-b7a2-44a4-9423-bdc24fc779e4",
   "metadata": {},
   "source": [
    "`-` $C_p, AIC, BIC$ 측도들은 선형모형 뿐 아니라 좀 더 일반적인 형태의 모형 하에서도 적절히 정의될 수 이씅며, 모형 선택에 활용될 수 있음.\n",
    "\n",
    "`-` 과거에는 보정측도들을 널리 사용하였으나, 계산능력의 향상으로 교차타당검증법(CV)도 매우 대중적으로 변함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4c070-86f1-4774-915b-570ba65efff7",
   "metadata": {},
   "source": [
    "### **D. One-standard-error rule**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeadf2ca-6f8c-48d4-87fb-74654d022d39",
   "metadata": {},
   "source": [
    "교차타당검증에는 데이터셋 분할에 따른 변동성이 존재할 수 있음 : CV에서 MSE의 표준오차$e$ 추정. 최적으로 판명된 모형의 test MSE에서 $e$이내의 test MSE를 가지는 모형들은 대략 비슷한 성능을 보이는 것으로 간주함.\n",
    "\n",
    "> 즉, test MSE의 최소값 $\\pm e$이내에서 test MSE를 가지고 있는 모형들 중 가장 단순한 모형을 최종 모형으로 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf484935-6957-43c2-8654-27afe4940fee",
   "metadata": {},
   "source": [
    "Anova t검정 안하면 감점?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847799d-697e-4707-a53f-0232630a766a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "위까지 중간고사 범위\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60cc67-0dca-45c8-99c0-8ce61258eb76",
   "metadata": {},
   "source": [
    "지금은 기말 발표 개인적으로 하는 거임. 배운 내용들을 종합하여 분석하고, 1페이지 정도의 포스터로 축약하여 발표하는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d7290e-4391-46ec-8066-e1553bec4655",
   "metadata": {},
   "source": [
    "### E. Shrinkage methods\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb097eb-6e15-49de-87d3-9c2af62db234",
   "metadata": {},
   "source": [
    "`-` 변수의 개수가 많아서 변수 전체를 쓰는 데 문제가 되는 상황\n",
    "\n",
    "* 완벽한 선형 결합으로 이뤄졌거나 변수의 개수가 너무 많아서 역행렬이 존재하지 않는 경우 -> 유일해가 존재하지 않음.\n",
    "* 다중공선성이 존재하는 경우 유일해가 존재하나 분산이 매우 큼\n",
    "\n",
    "> 계수 추정에서 특정한 바운더리에 모수가 들어간다고 가정하여 추정량 산출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443a5f3-7b4f-4e32-9098-5e9c2f36d46a",
   "metadata": {},
   "source": [
    "`-` Ridge regression\n",
    "\n",
    "> 원의 형태로 계수 추정 구간을 제약(L2-norm)\n",
    ">\n",
    "> 아래 식을 최소화하는 것을 목표로 함\n",
    "\n",
    "$$\\underset{i=1}{\\overset{n}{\\sum}} \\Bigg(y_i - \\beta_0 - \\underset{j=1}{\\overset{p}{\\sum}}\\beta_jx_{ij}\\Bigg)^2 + \\lambda \\underset{j=1}{\\overset{p}{\\sum}}\\beta_j^2$$\n",
    "\n",
    "> $\\lambda = 0$은 OLS와 동일, $\\lambda \\to \\inf$일수록 계수가 0에 가까워짐.\n",
    ">\n",
    "> 중요한 성질\n",
    ">\n",
    "> * 변수들 간 상관관계가 높을 경우 좋은 성능을 나타낼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b853e2e-616d-4020-aabb-cffc5084ff21",
   "metadata": {},
   "source": [
    "ex) $\\beta_0 = 2$\n",
    "\n",
    "일반적인 최소제곱추정 $\\hat\\beta_{01} = 3, \\hat\\beta_{02} = 1 \\to \\mathbb E(\\hat\\beta_0) = 2 : u.e$\n",
    "\n",
    "> 불편추정량\n",
    "\n",
    "Ridge Regression $\\hat\\beta_{01} = 2.4, \\hat\\beta_{02} = 1.2 \\to \\mathbb E(\\hat\\beta_0^R) = 1.8 : b.e$\n",
    "\n",
    "> 편의추정량, 하지만 분산이 줄어듦.\n",
    "\n",
    "$\\text{MSE}(\\hat\\beta) = Var(\\hat\\beta) + \\text{Bias}^2(\\hat\\beta)$가 줄어든다면, 더 좋은 거 ㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584408b-9923-47d9-9981-6106d829859e",
   "metadata": {},
   "source": [
    "`-` Lasso regression\n",
    "\n",
    "> 마름모꼴로 계수 추정 구간을 제약(L1-norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4d453-5ea2-4e1f-aa4f-fe9d1b2185e8",
   "metadata": {},
   "source": [
    "OLS, Ridge : 회귀계수가 0이 되는 경우는 거의 없음(사실상 불가능함)\n",
    "\n",
    "LASSO : 실제 값이 0인 계수(의미가 없는 변수)가 존재한다면, 일부를 0으로 만들 수 있음.\n",
    "\n",
    "> screening, 전체를 찾아내진 못하나, 최소한 몇 가지의 변수는 찾을 수 있다. 실제와 정확히 일치하냐는 것은 어렵다.\n",
    ">\n",
    "> 정확히 찾아내지 못해도, 평가 데이터에서의 예측오차를 가장 줄여줄 수 있는 방법이다. (선형 방법론들 중에서)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834440e-c08d-430f-bd46-538197405bf5",
   "metadata": {},
   "source": [
    "그래서 최적의 $\\lambda$값을 어떻게 선택할까?\n",
    "\n",
    "> Cross Validation을 사용.\n",
    ">\n",
    "> 많은 $\\lambda$ 값들에 대한 validation error를 확인해서 비교, validation error가 가장 작은 셋을 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c43f86-6d53-49ac-8765-b9883a8e1aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
