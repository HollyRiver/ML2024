{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cbd022-ae53-45a7-b18f-ee3dfdbf2e4b",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48af328-5077-4358-be01-2a1ad1c7bda8",
   "metadata": {},
   "source": [
    "> 가장 간단한 형태의 지도학습 방법, 양적변수의 예측을 위해 유용함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8592ce-865c-42f5-b196-61363d75839e",
   "metadata": {},
   "source": [
    "좁은 범위에서 양적변수의 예측을 위해 사용하지만, 일반적으로 평균을 알아내는 문제라고 얘기할 수 있다.\n",
    "\n",
    "많은 학습기법들이 선형회귀모형의 일반화 또는 확장의 관점에서 이해될 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc6154-3e9e-4e26-a3c1-8fb79db6d717",
   "metadata": {},
   "source": [
    "* 예측변수와 반응변수 간 관계가 있는가?\n",
    "* 변수 간 관계가 얼마나 강한가?(다중공선성까지)\n",
    "* **어떤 예측변수가 반응변수에 크게 기여하는가?**\n",
    "* 예측변수가 반응변수에 미치는 효과를 얼마나 정확히 예측할 수 있는가?\n",
    "* **반응변수의 미래 값을 얼마나 정확히 예측할 수 있는가?**\n",
    "* 변수간의 관계가 선형인가?\n",
    "* **예측변수들 사이에 일종의 시너지효과(상호작용)가 있는가?(교호작용 유무)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba227d-390f-40c6-9723-890ad2502ab0",
   "metadata": {},
   "source": [
    "`-` 단순선형회귀모형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6b718-66c2-4ad4-bd28-a1f697321bce",
   "metadata": {},
   "source": [
    "$$\\begin{align} Y & \\approx \\beta_0 + \\beta_1 X \\\\\n",
    "\\mathbb{E}(Y) & = \\beta_0 + \\beta_1 X\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d9faf-bb0c-4bb3-9c12-caaeccbe3e5a",
   "metadata": {},
   "source": [
    "> X는 상수로 간주해도 무방하나, 확률변수로서는 오차항 $\\epsilon$과 독립이여야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699a7b4-e1a9-47b7-9fa9-be66495562e8",
   "metadata": {},
   "source": [
    "`-` 회귀계수의 추정 : 최소제곱법 (Ordinary) Least squares\n",
    "\n",
    "$$\\begin{align}RSS & = \\overset{n}{\\sum} e_i^2 \\\\\n",
    "e_i & = y_i - \\hat y_i = y_i - \\hat \\beta_0 + \\hat \\beta_1 x_i\n",
    "\\end{align}$$\n",
    "\n",
    "> 본래 $\\mathbb{E}[(Y - \\hat Y)^2], ~ \\hat Y = \\mathbb{E}[Y|X]$, 기댓값을 최소화하는 것을 회귀계수로 추정해야 하나, 조건부 기댓값은 실제로 관찰할 수 없으므로 표본평균을 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219f3cd-7638-4556-be51-5d13ffd18fa1",
   "metadata": {},
   "source": [
    "$$\\begin{align} \\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\beta_0 - \\beta_1 x_i)^2 & = \\mathbb{L}(\\beta_0, \\beta_1) \\\\\n",
    "\\frac{\\partial\\mathbb{L}}{\\partial \\beta_0} & = \\frac{\\partial\\mathbb{L}}{\\partial \\beta_1} = 0 \\\\\n",
    "\\hat \\beta_1 & = \\frac{\\underset{i=1}{\\overset{n}{\\sum}}(x_i-\\bar{x})(y_i - \\bar{y})}{\\underset{i=1}{\\overset{n}{\\sum}}(x_i - \\bar x)^2} \\\\\n",
    "\\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\bar y)^2 & = \\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\hat y_i)^2 + \\underset{i=1}{\\overset{n}{\\sum}}(\\hat y_i - \\bar y)^2 = SSE + SSR \\\\\n",
    "\\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\hat y_i) & = 0, ~ \\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\hat y_i) x_i = 0\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f979e5-be4b-47ab-8537-9dd961f0de3d",
   "metadata": {},
   "source": [
    "> * $\\hat \\beta_1$의 분자 부분은 $\\bar x, \\bar y$를 무시하면 벡터 간 내적으로 취급할 수 있다. 따라서 기하학적으로 방향이 같다면 그 값이 커지게 된다.\n",
    "> * $\\hat y_i - \\bar y = \\hat \\beta_1(x_i - \\bar x)$, 절편을 제외한 회귀계수의 중요성이 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a967af0-4d9e-41f0-879a-e5315106c9f3",
   "metadata": {},
   "source": [
    "`-` 추정의 정확성 평가\n",
    "\n",
    "* 편의 bias : 많은 수의 데이터셋으로부터 적합된 직선을 반복해서 얻었을 때, 평균적인 직선이 실제 모형과 얼마나 다른가? 일치추정량의 경우 편의가 존재하긴 하지만 어쩌고...\n",
    "* 단순선형회귀모형에서 최소제곱법에 의해 얻어진 직선은 불편성unbiaseness이 성립한다.\n",
    "* 표준오차 : 추정의 불확실성 혹은 신뢰성(추정의 정확성 : precison TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e81634-0001-4a69-8be7-563eb5dd8071",
   "metadata": {},
   "source": [
    "`-` 표준오차의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319f69c-40f1-41bb-bee6-0c4f74e25cac",
   "metadata": {},
   "source": [
    "1. 신뢰구간의 구성\n",
    "\n",
    "$$\\hat \\beta_1 \\pm 2 \\cdot SE(\\hat \\beta_1)$$\n",
    "> $\\hat \\beta_1$이 (근사적으로) 정규분포를 따른다는 가정 하에서 유도됨.\n",
    "\n",
    "2. 가설검증\n",
    "\n",
    "$\\beta_1 = 0$을 검증하고자 할 때, 통계량은\n",
    "\n",
    "$$t = \\frac{\\hat \\beta_1 - 0}{SE(\\hat\\beta_1)}$$\n",
    "\n",
    "으로 계산되고 $t$분포를 이용하여 p-value 계산이 가능하다.\n",
    "\n",
    "> 평균이 0인 분포에서 0이 나온 거냐, 아니면 0이 아닌 분포에서 0이 나온거냐를 검정. 정확한 분포가 필요함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532d789-6961-4d58-8b44-5d5f6f95df25",
   "metadata": {},
   "source": [
    "`-` 모형의 정확성 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604df267-a82e-4b90-9d0d-b355d5f99f1a",
   "metadata": {},
   "source": [
    "* Residual Standard Error : 오차항의 표준편차의 추정치. MSE와 동일.\n",
    "\n",
    "$$RSE = \\sqrt{\\frac{RSS}{n-2}}$$\n",
    "\n",
    "* 결정계수 $R^2$ : 반응변수의 전체 변동 중 적합된 직선에 의해 설명되는 변동의 비율.\n",
    "\n",
    "$$R^2 = \\frac{TSS - RSS}{TSS}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98c7ac-b67e-4db1-b31b-ba7964791cbe",
   "metadata": {},
   "source": [
    "`-` Multiple Linear Regression\n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d5c8f-1166-400a-b1e7-21df7b5e02ce",
   "metadata": {},
   "source": [
    "### 모형 평가 및 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a764d49e-3663-42bf-8945-83ed79d03f48",
   "metadata": {},
   "source": [
    "`-` 가설검정 : 변수들 간의 연관성이 존재하는가?\n",
    "\n",
    "$$H_0 : \\beta_1 = \\cdots = \\beta_p = 0 ~ vs ~ H_1 : \\text{not} ~ H_0$$\n",
    "\n",
    "$$F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)} = \\frac{MSR}{MSE}$$\n",
    "\n",
    "> 귀무가설 하에서 $F$분포를 따름.\n",
    ">\n",
    "> 분모의 경우 선형 가정 하에서 기댓값이 $\\sigma^2$이다.\n",
    ">\n",
    "> 분자의 경우 $H_0$ 하에서 기댓값이 $\\sigma^2$이다. : SST - SSE의 분포가 카이제곱분포를 따름.\n",
    ">\n",
    "> $H_0$이 틀렸다면 분자가 $\\sigma^2$보다 큰 값을 가지게 되어 $F$값이 커진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918dadc0-3842-406b-a6b8-bd6948df6bab",
   "metadata": {},
   "source": [
    "`-` 어떤 변수가 더 중요한가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f06366-657d-4945-ae66-e58d4fa04c3b",
   "metadata": {},
   "source": [
    "* 의미없는 예측변수들이 존재할 수 있다.\n",
    "\n",
    "* 대부분 의미가 있다고 하더라도 예측변수의 수가 많은 경우 적절한 선택을 통해 모형에 포함되는 변수의 개수를 축소시키는 것이 도움이 된다는 것이 알려져있다. (다중공선성)\n",
    "\n",
    "* 변수선택을 위한 여러 방법 또는 측도가 존재한다.\n",
    "\n",
    "$$C_p, AIC, BIC, R^2_{adj}, \\cdots$$\n",
    "\n",
    "> 훈련 데이터에서만으로도 테스트 데이터에서 어느 정도의 성능이 나올 지 알 수 있는 방법이 없을까? 하는 상황에서 제시된 측도\n",
    "\n",
    "* 변수의 개수가 $p$개면 가능한 모형은 총 $2^p$개 -> 전진선택, 후진제거, 단계적선택법 등을 적절히 활용해야.\n",
    "\n",
    "* LASSO와 같은 축소추정법을 이용할 수도 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b39cb-3771-4572-a1f8-06e81a993bb7",
   "metadata": {},
   "source": [
    "`-` 모형 적합도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aeb3d4-7d00-4988-89bf-c304ecedcdb4",
   "metadata": {},
   "source": [
    "$R^2, RSE$ 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520ba27-f8ce-4f37-ba4b-69a1cfa62a58",
   "metadata": {},
   "source": [
    "`-` 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99ce6f-f98b-447b-89ea-03f5ec71e3e6",
   "metadata": {},
   "source": [
    "세 종류의 불확실성 존재\n",
    "\n",
    "1. 계수의 추정으로부터 오는 부정확성 (계수 추정량의 분산) : Reducible error. $Var(\\hat \\beta)$\n",
    "\n",
    "2. 선형성 가정은 실재에 대한 근사이므로 그 차이에서 오는 부정확성 : Model bias. $\\text{Bias}(\\hat \\beta)$\n",
    "\n",
    "3. $f$를 정확히 안다고 해도 오차로부터 발생하는 부정확성 : Irreducible error. $Var(y)$\n",
    "\n",
    "* 평균반응(Confidence Interval)에 대한 추정 vs 개별반응(Prediction Interval)에 대한 추정\n",
    "\n",
    "$$x^{\\top}\\hat\\beta \\pm t_{\\alpha/2}(n-p-1)\\times s.e.(x^{\\top}\\hat\\beta) : \\text{모수 f에 대한 신뢰구간}$$\n",
    "\n",
    "$$x^{\\top}\\hat\\beta \\pm t_{\\alpha/2}(n-p-1)\\times \\sqrt{s.e.(x^{\\top}\\hat\\beta)^2 + \\hat \\sigma^2} : \\text{개별 y에 대한 신뢰구간}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d693e-43a5-4c31-a2d1-6a61a5c7ef83",
   "metadata": {},
   "source": [
    "`-` Leverage\n",
    "\n",
    "훈련 데이터의 모든 관측치는 모형의 추정이나 예측에서 동일한 비중의 기여를 하는 것이 아님.\n",
    "\n",
    "> 각 관측치의 모형에 대한 영향력을 평가하는 측도 존재.\n",
    "\n",
    "* 단순선형회귀 Leverage\n",
    "\n",
    "$$\\frac1n + \\frac{(x_i-\\bar x)^2}{\\underset{l=1}{\\overset{n}{\\sum}}(x_l - \\bar x)^2}$$\n",
    "\n",
    "> $x_i$가 $\\bar x$에서 멀어질수록 값이 커짐\n",
    "\n",
    "* 중회귀 Leverage\n",
    "\n",
    "$$x_i^{\\top}(X^{\\top}X)^{-1}x_i$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
