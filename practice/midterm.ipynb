{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61402a8f-a033-4444-94eb-008f2c87db5f",
   "metadata": {},
   "source": [
    "**ANOVA?**\n",
    "\n",
    "분산분석표는 세 종류가 존재함.\n",
    "\n",
    "* Type 1 anova : 변수를 하나씩 늘려갔을 때, 유의한지 여부에 대한 검정\n",
    "* Type 2 anova : 전체 모형을 적합했을 때 개별 변수에 대한 유의성 검정\n",
    "* Type 3 anova : 다른 변수들의 효과를 제어했을 때, 유의한지 여부에 대한 검정\n",
    "\n",
    "`anova_lm(model, typ=int)`\n",
    "\n",
    "**Mallow's $C_p$?**\n",
    "\n",
    "교호작용 : 일반적으로 2차 교호작용을 나타냄."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334078d-765c-4b79-b90f-5f0a4d575541",
   "metadata": {},
   "source": [
    "## **강의 요약**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee62919-3d45-48fa-96d1-7084ceedcec3",
   "metadata": {},
   "source": [
    "### 기계학습의 정의\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17d54f-a198-4110-81c1-91e675e0bc22",
   "metadata": {},
   "source": [
    "예측이 있고, 추론이 있음. 예측은 conditional expectation을 맞추는 것이다. 조건부 평균을 맞추는 문제.\n",
    "\n",
    "non-parametric으로 가면 해석은 힘들지만 예측은 잘 될 가능성이 높다.\n",
    "\n",
    "지도/비지도\n",
    "\n",
    "회귀/분류\n",
    "\n",
    "모든 문제를 다 잘 풀 수 있는 방법론은 존재하지 않는다.\n",
    "\n",
    "평가측도 : 평균제곱오차 MSE 기본 형태\n",
    "\n",
    "훈련과 평가가 뭔지\n",
    "\n",
    "오버피팅/언더피팅에 대한 개념\n",
    "\n",
    "> 형태는 충분히 쫓아가고 있으나, 훈련 데이터에 너무 의존하면서 분산이 커져 새로운 데이터를 제대로 예측하지 못하는 상태\n",
    "\n",
    "평가 MSE의 기대값의 분해\n",
    "\n",
    "> irreducible error : 어떤 모형을 선택하든 control할 수 없는 error\n",
    ">\n",
    "> reducible error : 모형이 단순하면 편의는 커지지만 분산은 줄어들 수 있다. 모형이 복잡하면 편의는 작아지나 분산이 커질 수 있다.\n",
    ">\n",
    "> 적당한 타협이 필요하다. trade off\n",
    "\n",
    "오류율 : classification의 문제. accuracy의 반대.\n",
    "\n",
    "베이즈 오류 : 확률을 정확히 알지 못해도 베이즈 오류를 달성할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a661aeb-28e1-4a73-9aac-02f6b65bb9ab",
   "metadata": {},
   "source": [
    "### 선형회귀\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218cf9a-4a52-4813-bb8e-b001fdec8316",
   "metadata": {},
   "source": [
    "RSS, t-test, RSE 시험문제에선 헷갈리게 나오진 않을 거예요.\n",
    "\n",
    "가설검정 방법 F-statistics\n",
    "\n",
    "예측을 할 때의 신뢰구간\n",
    "\n",
    "래버리지\n",
    "\n",
    "범주형 변수 -> 가변수화\n",
    "\n",
    "optimization은 이번 범위는 아님."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d150988-3a7c-463f-8303-508889604ac1",
   "metadata": {},
   "source": [
    "### 분류\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37199953-02f9-4211-8222-1541d4371a4c",
   "metadata": {},
   "source": [
    "결론적으로 확률을 예측하는 문제이다. 로지스틱은 모형을 로짓으로 만들어야만 한다.\n",
    "\n",
    "로짓을 사용해야 하는 이유\n",
    "\n",
    "패키지에서 구동한 결과 : 회귀계수들 해석하는 것(로짓을 다시 확률로 변경 : 시그모이드)\n",
    "\n",
    "변수가 세 개 이상인 경우 LDA 사용하는 게 나음.\n",
    "\n",
    "LDA : x의 조건부 확률분포, 판별함수\n",
    "\n",
    "LDA 샘플에서의 계산(베이즈 분류기로의 근사)\n",
    "\n",
    "QDA : 선형이 아님.\n",
    "\n",
    "Classification에서의 성능 평가 : 혼동행렬을 이용한 여러 성능 지표\n",
    "\n",
    "> **민감도, 특이도, ROU curve, AUC**\n",
    ">\n",
    "> 베이즈 분류기는 전체 오류율을 최소화시키려 하기 때문에 특정 범주에 대해서는 좋은 성능을 담보하지 않을 수 있음.\n",
    ">\n",
    "> 임계치 조정에 따른 민감도와 특이도의 변화\n",
    "\n",
    "Naive bayes : x의 조건부 결합확률밀도함수를 구하기 어려울 때 독립을 가정하고 결합확률밀도함수를 곱으로 계산\n",
    "\n",
    "분류기의 성능 비교 : 성질과 순위. 어느 것이 가장 단순하고 어느 것이 가장 복잡한지. 언더피팅과 오버피팅."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570c699-3a72-4077-b0f5-713aed2a8c23",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9fffc-9f54-4839-a9ed-c3d69b0d3cd0",
   "metadata": {},
   "source": [
    "LOOCV에서 $\\text{MSE}_i$는 그냥 지우고 생각해도 됨. 굳이 해당 notation을 동원할 필요는 없음.\n",
    "\n",
    "CV에서 예측 오차를 추정할 때, fold를 쓰면 여러 개의 오차를 비교.\n",
    "\n",
    "f-fold의 MSE 평균의 표준오차를 구해서 막대를 늘림\n",
    "\n",
    "붓스트랩 샘플링에서 제일 중요한 것 : 원래 모분포에서 추정해야 하는데 표본을 샘플링해서 파라미터를 추정한다. 기본 개념 정도만 알면 될 것 같아요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5562b48a-9d7e-43db-badc-6c2c11e3e36e",
   "metadata": {},
   "source": [
    "### 선택법\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572cfc23-aecd-4572-a9dc-71189fe24d1e",
   "metadata": {},
   "source": [
    "전진/후진 등에서 몇 번 모형을 적합해야 하는가?\n",
    "\n",
    "> 전진선택법/후진제거법 : 하다가 끝까지 안가고, 더 해봤자 도움이 되지 않을 것 같으면 중간에서 끊음. 변수가 몇개인 것까지 fitting을 했다 -> 그럼 몇 개의 모형을 적합했는가? 이정도\n",
    "\n",
    "Cp, AIC, BIC\n",
    "\n",
    "> Cp는 모형과 상관 없이 똑같은 $\\hat \\sigma$를 써야 함. 원래는 모분산을 알아야 함.\n",
    "> \n",
    "> AIC, BIC에서는 모형에 따라 다른 $\\hat \\sigma$를 써야 함.\n",
    "\n",
    "조정된 Rsq\n",
    "\n",
    "RSS, Rsq 사용 시 별로 안좋음.\n",
    "\n",
    "교차타당검증 : 훈련데이터와 validation set이 필요하다.\n",
    "\n",
    "one-standard-error rule. 1-se rule의 개념\n",
    "\n",
    "> CV error의 경우 각각의 블럭에서 예측오차를 계산하고 그 평균을 사용한 것.\n",
    ">\n",
    "> 평균의 표준오차를 계산할 수 있음. test error가 가장 작은 모형의 값에서 표준오차 범위 내의 값을 가지는 test erorr가 있으면 모두 비슷한 성능을 보이는 것으로 간주함. 여기서 가장 단순한 모형을 선택한다.\n",
    ">\n",
    "> 교차검증오차가 훈련데이터 전체를 안써서 약간의 bias가 존재하기 때문에 보정을 하기 위해서, 또 간단한 걸 선택하기 위해서."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
