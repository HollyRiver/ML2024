{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef98de0-3153-44fc-aede-1a7b3d7aa61b",
   "metadata": {},
   "source": [
    "## 1. 기계학습의 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580846ed-93d5-4117-a674-e24e41128ec4",
   "metadata": {},
   "source": [
    "`-` 예측과 추론\n",
    "\n",
    "* 예측 : 주어진 예측변수의 값에 대하여 반응변수에 대한 예측값을 얻을 수 있다. 예측에만 목적이 있을 경우 정확한 함수 형태를 아는 것은 중요하지 않다. 궁극적인 목표는 낮은 예측오차이다.\n",
    "* 추론 : 예측변수와 반응변수의 관계를 정확히 이해하기 위한 것으로, 추론에 목적이 있을 경우 함수 형태는 어느 정도 표현 가능해야 한다.\n",
    "\n",
    "`-` 비모수적 모형의 경우 추론은 힘들지만 예측은 잘 될 가능성이 높다.\n",
    "\n",
    "`-` 지도학습과 비지도학습의 차이는 반응변수의 유무이다.\n",
    "\n",
    "`-` 회귀와 분류의 차이는 반응변수가 양적인지 질적인지에 대한 것이다.\n",
    "\n",
    "`-` 모든 문제를 다 잘 풀 수 있는 방법론은 존재하지 않는다.\n",
    "\n",
    "`-` 평균제곱오차\n",
    "\n",
    "$$\\text{MSE} = \\frac1n \\underset{i=1}{\\overset{n}{\\sum}}(y_i - \\hat y_i)^2$$\n",
    "\n",
    "* 훈련 데이터는 모형의 추정에 사용되며, 평가 데이터는 예측의 정확도를 위해서 사용된다.\n",
    "* 훈련 데이터의 MSE를 줄이는 것을 목표로 하면서도 평가 데이터에서도 높은 성능을 보여야 한다.\n",
    "* 훈련 MSE가 과도하게 작아지는 모형의 경우 평가 MSE가 오히려 증가한다. 모형이 훈련 데이터의 적합에 지나치게 집중되어 예측에서의 변동을 증가시키기 때문이다. 이를 과적합되었다고 한다.\n",
    "\n",
    "`-` 오버피팅 / 언더피팅\n",
    "\n",
    "* 모형의 적합이 훈련 데이터에 너무 의존하면서 분산이 커져 새로운 데이터를 제대로 예측하지 못하는 상태.\n",
    "* 모형이 데이터의 형태를 제대로 따라가지 못하고 있는 상태.\n",
    "\n",
    "`-` 평가 MSE 기대값의 분해\n",
    "\n",
    "* irreducible error : 계수 추정에 따른 분산과 모형의 편의, 적절한 모형을 택하여 줄일 수 있는 오차\n",
    "* reducible error : 오차항에 의한 에러로, 최적의 모형을 적합하여도 피할 수 없는 오차\n",
    "\n",
    "`-` 베이즈 오류 : 집단에 속할 확률이 가장 높은 것으로 분류했을 때의 오류. 확률을 정확히 알지 못해도 분류기가 베이즈 오류를 달성할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd0b553-5276-4739-9bf1-9a421f747859",
   "metadata": {},
   "source": [
    "## 2. 선형회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6953e-b1ec-4174-8b21-44e92ee780dd",
   "metadata": {},
   "source": [
    "`-` 가설검정\n",
    "\n",
    "* 표준오차를 사용하여 가설검정을 할 수 있다. (t-test)\n",
    "* 잔차제곱합 RSS와 총제곱합 TSS를 이용하여 모형의 유의성을 검정할 수 있다. (F-test)\n",
    "* 변수 추가에 있어 모형을 확장하는 것이 통계적으로 유의한지 알기 위해 \n",
    "\n",
    "`-` 표준오차\n",
    "\n",
    "* 표준오차는 가설검정 및 신뢰구간의 구성에 활용될 수 있다.\n",
    "\n",
    "`-` 래버리지\n",
    "\n",
    "* 모든 데이터가 모형의 적합에 기여하는 정도는 같지 않다. 특정 데이터가 모형의 적합에 지나치게 많은 영향을 미친다면 이를 래버리지 포인트로 간주할 수 있다.\n",
    "\n",
    "`-` 범주형 변수 처리\n",
    "\n",
    "* 설명변수가 범주형 변수일 경우 가변수화하여 수치적으로 처리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd292fe5-3eba-45a2-81bc-f45b021eca4b",
   "metadata": {},
   "source": [
    "## 3. 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471ac82-3e11-4f52-b0e8-4d08ed0248a2",
   "metadata": {},
   "source": [
    "`-` 분류는 결론적으로 확률을 예측하는 문제이다.\n",
    "\n",
    "`-` 로지스틱 회귀분석은 모형을 로짓으로 만들어야만 한다. 데이터의 수가 상당히 많을 경우 선형회귀로 적합해도 나름대로의 퍼포먼스가 나올 수 있다.\n",
    "\n",
    "`-` 로짓을 사용해야 하는 이유\n",
    "\n",
    "* 확률을 예측하는 문제에서 일반적인 회귀모형을 사용할 경우 예측확률이 0과 1 사이를 벗어날 수 있게 된다. 따라서 확률을 0에서 1 사이의 값으로 만들어주기 위한 모형이 필수적이다.\n",
    "* 변수가 세 개 이상인 경우 로지스틱 회귀분석을 사용하기 어렵다.\n",
    "\n",
    "`-` 판별분석\n",
    "\n",
    "* x의 조건부 확률분포를 이용하여 판별함수를 구성하고 최적의 확률을 계산한다.\n",
    "* LDA를 샘플에서 계산하여 베이즈 분류기로 근사할 수 있다.\n",
    "* QDA의 decision boundary는 선형이 아니다.\n",
    "\n",
    "`-` 분석에서의 성능 평가\n",
    "\n",
    "* 민감도, 특이도\n",
    "* ROU Curve, AUC\n",
    "* 베이즈 분류기는 전체 오류율을 최소화시키려 하기 때문에 특정 범주에 대해서는 좋은 성능을 담보하지 못할 수 있다. 따라서 임계치를 적절히 조절하여 민감도와 특이도를 조정해야 한다.\n",
    "\n",
    "`-` Naive bayes\n",
    "\n",
    "* 예측변수가 많을 경우 이들의 조건부 결합확률분포를 구하기 어렵다. 따라서 독립을 가정하고 결합확률분포를 개별 변수들의 조건부 확률분포의 곱으로 계산한다.\n",
    "\n",
    "`-` 로지스틱 $\\approx$ LDA < QDA < KNN 순으로 복잡한 모형이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8f17c-70ec-4235-8177-4e089001f559",
   "metadata": {},
   "source": [
    "## 4. 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652ce6d-0859-4717-88f1-6039c18b479e",
   "metadata": {},
   "source": [
    "`-` k-fold CV\n",
    "\n",
    "* 예측 오차 추정 시 fold를 쓰면 여러 개의 오차를 비교하게 된다.\n",
    "* k-fold의 MSE 평균의 표준오차를 구해서 변동을 계산할수도 있다.\n",
    "\n",
    "`-` 붓스트랩\n",
    "\n",
    "* 원래 모분포에서 추정해야 하는 모수를 표본을 리샘플링하여 추정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e15c76-e6f2-4372-bc48-4f3ef761e09e",
   "metadata": {},
   "source": [
    "## 5. 선택법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c009861-531c-46cc-a872-0b4f406f4243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
