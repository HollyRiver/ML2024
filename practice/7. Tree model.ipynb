{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. 의사결정나무 Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X가 가질 수 있는 값의 공간을 분할해서, 분할한 공간에 Y의 평균값을 하나의 예측값으로 할당한다.\n",
    "\n",
    "> 파티션이 너무 작을 경우, bias는 작아지겠으나 예측에의 분산이 매우 커진다.(Overfitting)\n",
    ">\n",
    "> 적당한 trade-off가 필요하다.\n",
    "\n",
    "`-` 논점\n",
    "\n",
    "1. 얼마나 잘게 쪼갤 것인가?\n",
    "2. 예측의 러프함을 어떻게 해결할 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 나무 모형은 예측변수들의 공간(예측변수가 가질 수 있는 값들의 집합)에 대한 층화적 분할에 근거한다.\n",
    "\n",
    "> 유한한 공간.\n",
    "\n",
    "* 주어진 관측치에서의 예측값은 해당 관측치가 속한 예측변수의 영역(분할된 공간)에서의 반응변수들의 평균값으로 주어진다.(분류 문제도 마찬가지)\n",
    "\n",
    "* 간단하고 해석에서 장점이 있다.\n",
    "\n",
    "> 어떤 노드를 통과해야 해당 값으로 귀결되는가? -> 분류 등에서 체크하기 쉬움.\n",
    "\n",
    "* 다른 기계학습 방법들에 비해 좋은 성능을 보이지 못하는 경우가 많다.\n",
    "\n",
    "> 급격한 변화를 보이는 상황에서 예측오차가 커짐\n",
    ">\n",
    "> 새로운 자료의 투입에 민감함, 로버스트하지 못한 모형임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. 공간 분할의 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 분할된 공간 혹은 나무에서의 최하단 부분을 terminal nodes / leaves라 한다.\n",
    "\n",
    "* Binary Splitting : 전체 공간을 하나의 예측변수를 기준으로 두 공간으로 분할한다.\n",
    "\n",
    "> 단, 하위 분할시에는 전체 공간이 아니라 이미 분할된 공간에 Binary Splitting을 적용함(층화적 분할)\n",
    "\n",
    "* 적절한 Stopping Rule에 따라 분할을 중지한다.\n",
    "\n",
    "`-` 가장 큰 제곱합의 감소를 가져다주는 변수와 분기점을 선택\n",
    "\n",
    "$$\\underset{i\\in R}{\\sum}(y_i - \\bar y)^2 - \\underset{k=1}{\\overset{2}{\\sum}}\\underset{i\\in R_k}{\\sum}(y_i - \\bar y_k)^2$$\n",
    "\n",
    "&nbsp; 전체의 오차제곱합과 노드 별 오차제곱합의 합. 해당 차이를 크게 만들어야 함.\n",
    "\n",
    "$$RSS = \\underset{j=1}{\\overset{J}{\\sum}}\\underset{i \\in R_j}{\\sum}(y_i - \\hat y_{R_j})^2$$\n",
    "\n",
    "&nbsp; 위를 최소화하는 예측변수의 값들을 선택하는 것을 목표로 함.\n",
    "\n",
    "> $\\hat y_{R_j}$는 $R_j$에서의 예측변수 평균, $R_j$는 terminal nodes의 영역들.\n",
    ">\n",
    "> 각각의 노드의 값은 노드 평균에 가까워지도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 나무모형은 예측성능은 좋을 수 있지만, 과적합 문제가 발생할 수 있음.\n",
    "\n",
    "> 리프의 샘플이 너무 작은 상황이 발생하면 분산이 커짐 -> 최소한 각각의 리프에 몇 개 이상의 데이터가 있어야 한다고 제약 걸 수 있음\n",
    "\n",
    "* 해석은 명확하나, 예측력의 관점에서는 그닥 좋은 것은 아님.\n",
    "\n",
    "* 나무의 크기는 모형의 복잡도와 연결된다. -> 적절히 모형을 단순화시켜줄 필요가 있다.\n",
    "\n",
    "`-` 해결방법\n",
    "\n",
    "> RSS의 감소가 특정 수준 이하로 떨어지면 중단하는 방법 : 이후 큰 RSS 감소를 불러일으키는 분할을 무시하게 될 수 있음.\n",
    ">\n",
    "> 나무를 매우 크게 키운 뒤 적절히 가지치기하여 단순화시키는 방법 : test error를 작게 하는 subtree를 찾음. 더 선호되는 방법.\n",
    "\n",
    "`-` Cost complexity Pruning\n",
    "\n",
    "* $\\alpha$의 적절한 그리드를 선택하고, 각 $\\alpha$에 대하여 다음을 최소화시키는 나무를 찾는다.\n",
    "\n",
    "$$\\underset{m=1}{\\overset{|T|}{\\sum}}\\underset{x_i \\in R_m}{\\sum}(y_i - \\hat y_{R_m}) + \\alpha|T|$$\n",
    "\n",
    "$|T| : $ Number of terminal node\n",
    "\n",
    "> 리프 노드를 T개로 증가시켰을 때 RSS 감소분이 모형의 복잡성 증가분보다 커야 한다.\n",
    ">\n",
    "> 선택된 $\\alpha$에 대응되는 나무가 최종 선택되는 모형을 선택한다.\n",
    ">\n",
    "> 노드의 개수를 고려하여 최적화 함수를 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쪼갤 수 있는 모든 노드를 쪼갠 후, 병합하는 식으로 가지치기를 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Classification trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률을 예측하고, 그 다음 범주를 예측함.\n",
    "\n",
    "빈도의 이질성을 중시\n",
    "\n",
    "> 얼마나 노드 안에 같은 class가 많이 있는지를 중요시한다. MSE와 다른 것을 사용하여 공간을 분할한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Measures for splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 오분류율 Classification error rate\n",
    "\n",
    "$$E = 1 - \\underset{k}{\\max}(\\hat p _{mk})$$\n",
    "\n",
    "> $\\hat p _{mk}$는 m노드에서 k범주의 비율\n",
    ">\n",
    "> 해당 값을 줄이는 것을 목표로 함. 한 노드에 같은 범주의 값만 존재한다면 0이 됨.\n",
    ">\n",
    "> 최대값에만 의존하며, 민감한 측도가 아님.\n",
    "\n",
    "* Gini index\n",
    "\n",
    "$$G = \\underset{k=1}{\\overset{K}{\\sum}}\\hat p_{mk}(1-\\hat p_{mk})$$\n",
    "\n",
    "> 해당 값이 0이 되려면, 한 노드에 같은 범주의 값만 존재해야 함.\n",
    "\n",
    "* Entropy\n",
    "\n",
    "$$D = - \\underset{k=1}{\\overset{K}{\\sum}} \\hat p_{mk} \\log \\hat p_{mk}$$\n",
    "\n",
    "> 해당 값이 0이 되려면, 확률이 0/1이여야 함.\n",
    ">\n",
    "> 해당 측도를 가장 많이 사용함.\n",
    "\n",
    "지니 인덱스와 엔트로피는 바이너리에서 0.5일 때 최대"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini index와 Entropy가 주로 사용된다 : 하나의 노드가 두 개의 노드로 분할될 때, 가장 Gini index / Entropy가 많이 줄어드는 경우를 선택.\n",
    "\n",
    "> 해당 공간의 순도가 높을수록 0에 가까운 값. 즉, 불순도를 최소화시키는 방향으로 분할이 이뤄짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. 트리 / 선형 모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 각각 예측\n",
    "\n",
    "* Linear model\n",
    "\n",
    "$$f(X) = \\beta_0 + \\sum X_j \\beta_j$$\n",
    "\n",
    "* Regression trees\n",
    "\n",
    "$$f(X) = \\sum c_m I(X \\in R_m)$$\n",
    "\n",
    "$R_m$은 예측기의 공간\n",
    "\n",
    "> 실제 관계가 선형이 아니면, 나무 모형이 선형 모형보다 우수하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 나무 모형의 장단점\n",
    "\n",
    "* 장점\n",
    "\n",
    "> 모형에 대한 해석과 설명이 매우 직관적이고 간단\n",
    ">\n",
    "> 시각적으로 표현이 용이\n",
    ">\n",
    "> 예측변수에 범주형 변수가 있을 때, 가변수 처리가 필요하지 않음\n",
    "\n",
    "* 단점\n",
    "\n",
    "> 예측성능이 좋지 못한 경우가 많음\n",
    ">\n",
    "> 모형의 분산이 커서 robust하기 않은 경우가 많음. **데이터가 조금만 바뀌어도 생성되는 모형이 크게 변할 수 있음.**\n",
    "\n",
    "트리를 그대로 사용할 경우, 미분도 안되고 변화의 경계가 너무 많아 함수의 형태가 부드럽게 이어지지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **G. Ensemble methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging : Bootstrap aggregation**. bootstrap의 통합\n",
    "\n",
    "> 분산은 관측 자료의 randomness 때문에 발생함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 만약 모집단으로부터 여러 개의 훈련자료를 얻을 수 있고, 이로부터 여러 개의 모형을 얻을 수 있다면, 이로부터 주어지는 average prediction에 의해 모형의 분산을 줄일 수 있다.\n",
    "\n",
    "* 보통은 한 set의 자료만이 주어지게 되므로, 대신 Bootstrap을 이용하여 한 set의 자료로부터 여러 개의 훈련자료를 생성해 낼 수 있다.\n",
    "\n",
    "$X_1, \\cdots, X_n$이 어떤 모집단으로부터의 i.i.d random sample이라 할 때, 이로부터의 복원추출로 같은 size의 표본을 여러 개 만들어낼 수 있다.\n",
    "\n",
    "위 과정을 총 $B$번 반복하면 총 $B$개의 bootstrap sample이 얻어지고, 각 sample을 훈련자료로 하여 $\\hat f^{*, 1}, \\cdots, \\hat f^{*, B}$개의 함수를 얻으면 다음과 같이 최종 예측함수를 구성할 수 있다.\n",
    "\n",
    "$$\\hat f_{\\text{bag}} (x) = \\frac1B \\sum \\hat f^{*, b}(x)$$\n",
    "\n",
    "즉, $x$값에서의 예측값들의 평균을 예측값으로 나타낸다.\n",
    "\n",
    "$B$를 선택하는 것에서 문제가 있다. 많이 쓸수록 좋으나, 리소스 문제 때문에 적당한 개수를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Bagging의 효과\n",
    "\n",
    "* 각 나무들을 prunning하지 않아도 된다. 즉, 각 나무들의 분산이 커지더라도 편의를 작게 가지도록 한다. -> 최적의 $\\alpha$따위는 선택하지 않고, 그냥 한다.\n",
    "\n",
    "* 여러 개의 샘플링을 할 경우, 노드를 매우 작게 만든다.\n",
    "\n",
    "* Bagging은 여러 회귀방법들에서 예측력의 향상을 가져올 수 있으나, 특히 나무 모형에서 효용이 매우 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Bagging for classification\n",
    "\n",
    "* 분류 문제에서는 예측값이 class로 주어지므로, 이를 평균내는 것은 의미가 없다.\n",
    "* Majority voting : B개의 개별 나무들의 예측값 중 가장 다수를 차지하는 class로 예측값을 할당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Out-of-Bag error estimation\n",
    "\n",
    "* Bagging 수행 시 특정 나무의 적합에 사용되지 않는 관측지들이 평균적으로 전체의 약 1/3정도 됨.\n",
    "\n",
    "> i번째 관측치에 대한 test error를 추정하고자 할 때, $B$개의 나무모형 중 i번째 관측치를 적합에 사용하지 않은 약 $B/3$개의 나무들에 의한 에측치를 이용할 수 있음.\n",
    "\n",
    "* 모든 관측치에 대하여 위와 같은 과정을 수행하여 최종 test error를 추정함.\n",
    "\n",
    "> CV 등, 계산이 많이 필요한 절차를 피할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **Variable importance measure**\n",
    "\n",
    "* 다른 형태의 여러 나무를 결합하면, 모형을 해석하는 것은 거의 불가능\n",
    "* 나무들을 생성할 때, 어떤 변수들이 RSS / Gini index 등의 큰 감소를 가져왔는지를 요약한 값으로 변수의 중요도 판단 가능\n",
    "\n",
    "> 해석을 하기 위한 도구에 불과. 완벽한 해석의 지표는 아님.\n",
    "\n",
    "* 나머지 변수를 병합하고, 특정 변수(수치형)가 증가할 때, 반응변수의 평균이 어떻게 바뀌는지를 파악하는 방법으로 해석할 수도 있음 -> PDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 상관성과 averaging에 따른 분산 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bagging으로 예측력의 향상을 기대할 수 있는 이유는 분산의 감소를 가져오기 때문임.\n",
    "* 예측변수들 중 아주 강력한 소수의 예측변수들이 존재하여, 나무모형 생성 시 이 변수들을 기준으로 분할이 이뤄진다면, 나무모형 간 유사성이 커진다.\n",
    "* B개의 나무모형 간 유사성이 크게 된다면, 모형들 간의 correlation이 커져 final model의 예측력 향상에 부정적인 영향을 미치게 된다.(다양성 감소 -> 분산 증가)\n",
    "\n",
    "> 확률변수 간 양의 상관이 강하면, averaging에 의한 분산 감소량이 줄어든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 따라서, 나무모형 간 유사성이 작도록, Bootstrap sampling을 한 뒤, 후보 변수 선택 자체도 임의로 추출하면, 나무모형 간 유사성이 줄어들 것이다.\n",
    "* 중요한 변수를 제외한 나무 모형은 약한 모형이 될 것이나, 이런 모형들의 평균을 사용하는 것이 더 좋은 성능을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forests**\n",
    "\n",
    "> Bootstrap에 의해 생성되는 나무들간의 상관성을 제거함으로써, 최종 예측모형의 분산을 획기적으로 감소시키고자 하는 방법.\n",
    "\n",
    "* 소수의 강력한 예측변수에 의해 모든 나무모형이 유사해지는 것을 막기 위해서 매번 분할시마다 $p$개의 예측변수 중 일부인 $m < p$개의 예측변수들만 분할 기준의 후보로 삼는다.\n",
    "* 회귀모형에서는 $m = p/3$, 분류모형에서는 $m = \\sqrt{p}$를 흔히 사용한다.\n",
    "* 변수의 개수가 매우 많아도, 그 중 일부만 사용하여 final model의 예측력 향상으로 이어질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **H. Ensemble : Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기본 접근 방법 : 하나의 좋은 learner보다, 최소 조건만 만족하는 여러 개들의 약한 learner들로 더 좋은 결과를 얻을 수 있는가?\n",
    "* 독립적인 약한 learner들은 분산을 줄일 순 있으나, 복잡한 연관관계로 나타나는 편향을 없애지 못함.\n",
    "\n",
    "> 기본 생각 : 협업을 통한 강화."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 최초의 Boosting 알고리즘 : AdaBoosting\n",
    "\n",
    "* binary target $y \\in \\{-1, 1\\}$\n",
    "* initial weights $w_{1,1}, \\cdots w_{1,n} = \\frac1n$\n",
    "* Error function $E(f(x_i), y_i) = e^{-y_i f(x_i)}$\n",
    "> exponential loss. 똑같은 값이 나오면 1, 다른 값이면 -1이므로, 해당 loss를 줄이기 위해서는 y와 f(x)가 최대한 같은 값이여야 함.\n",
    "\n",
    "exponential loss가 그렇게 좋은 loss는 아니지만,,, 원리를 잘 설명해주는 알고리즘이라 처음 소개함 ㅇㅇ.\n",
    "\n",
    "* Find weak learner that minimizes $\\epsilon_t$, WSE for misclassified points $\\epsilon_t = \\underset{h_i(x_i) \\neq y_i}{\\sum} w_{i, t}$\n",
    "\n",
    "* choose $\\alpha_t = \\frac12 \\ln (\\frac{1-\\epsilon_t}{\\epsilon_t})$ -> error가 크면, $\\alpha$를 줄이고, 크면 키운다.\n",
    "\n",
    "> $\\epsilon_t > 0.5$이면, $\\alpha_t$가 음수가 된다. 이런 애들은 안쓴다. (무작위로 예측한 것보다 성능이 안좋음.)\n",
    "\n",
    "* Add to ensemble : $F_t(x) = F_{t-1}(x) + \\alpha_t h_t(x) = \\alpha_1 h_1(x) + \\cdots + \\alpha_t h_t(x)$\n",
    "\n",
    "> learner 하나하나가 차지하는 비중이 다르다. 현 상태에서 error가 크면, 모형의 가중치가 작아진다.\n",
    "\n",
    "* Update weights\n",
    "\n",
    "> $w_{i, t+1} = w_{i, t} e^{-y_i \\alpha_t h_t(x_i)}$ -> 맞춘 point의 weight가 작아지고, 못맞추면 weight가 커진다. 즉, 이후 적합에 있어 못맞춘 포인트들의 가중치를 더 크게 본다.\n",
    "\n",
    "정리하면\n",
    "\n",
    "* 오분류율(exponential loss)이 낮은 learner에 더 많은 가중치를 부여하도록 하여, 이들을 합하여 모형을 구성한다.\n",
    "* 이전 모형에서 맞추지 못한 데이터 포인트에 대해서 가중치를 더 부여하고, 맞춘 데이터 포인트에 대해서 가중치를 줄인다. 해당 가중치는 이후 모형에서 sequential하게 갱신된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 중요한 부분\n",
    "\n",
    "> 샘플 하나하나가 가중치를 가지고 있으며, 이 가중치는 이전 모형에서 정분류되었을 경우 감소한다.\n",
    ">\n",
    "> 각 learner는 가중치가 큰 샘플들을 잘 맞추는 것에 집중한다. 가중치가 큰 샘플들을 잘 맞춰야 오차가 감소한다.\n",
    ">\n",
    "> 각 learner의 비중은 가중 예측오차로부터 계산된다.\n",
    ">\n",
    "> 즉, 부스팅은 이전 결과에 밀접하게 연관되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이론적 배경 1\n",
    "\n",
    "> 손실함수 $\\exp(-y F(x))$\n",
    ">\n",
    "> 예측의 업데이트 $F_k \\rightarrow F_{k-1} + \\alpha_k h_k$\n",
    "\n",
    "$\\alpha_k$ 선택의 유도\n",
    "\n",
    "$$\\begin{align} l & = \\underset{i}{\\sum} w_{i, k-1} \\exp(-\\alpha_k y_i h_k(x_i)) \\\\\n",
    "& = \\underset{i:y_i = h_k(x_i)}{\\sum} w_{i, k-1} \\exp(-\\alpha_k y_i h_k(x_i)) \\\\\n",
    "& ~~~~ + \\underset{i:y_i \\neq h_k(x_i)}{\\sum} w_{i, k-1} \\exp(-\\alpha_k y_i h_k(x_i)) \\\\\n",
    "& = \\underset{i:y_i = h_k(x_i)}{\\sum} w_{i, k-1} \\exp(-\\alpha_k) \\\\\n",
    "& ~~~~ + \\underset{i:y_i \\neq h_k(x_i)}{\\sum} w_{i, k-1} \\exp(\\alpha_k) \\\\\n",
    "\\\\\n",
    "\\frac{\\partial l}{\\partial \\alpha_k} & = \\underset{i:y_i \\neq h_k(x_i)}{\\sum} w_{i, k-1} \\exp(\\alpha_k) \\\\\n",
    "& ~~~~ - \\underset{i:y_i = h_k(x_i)}{\\sum} w_{i, k-1} \\exp(-\\alpha_k) \\\\ \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "위 식을 0으로 하여 아래를 유도할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Boosting의 중요한 성질"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tree의 개수를 상당히 늘려도, test error가 급격히 증가하지 않음. train error와 유사하게 이동."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Regression의 경우, 마지막 잔차를 0에 가깝도록 만들도록 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 개별 관측치의 예측값을 Weighted sum 할 때, 양수면 1, 음수면 -1로 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gradient Boosting Machine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측값과 실제값의 차이를 Gradient를 이용하여 구하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function\n",
    "\n",
    "$$l(y_i, f(x_i))$$\n",
    "\n",
    "> 결국 loss function을 최소화하는, 최적화의 문제로 치환 가능.\n",
    "\n",
    "$F_0(x) = \\underset{\\gamma}{\\text{arg min}} \\sum L(y_i, \\gamma)$\n",
    "\n",
    "* 유사 잔차 pseudo-residuals\n",
    "\n",
    "$$r_{im} = - \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}$$\n",
    "\n",
    "* 학습률 최적화\n",
    "\n",
    "$$\\gamma_m = \\underset{\\gamma}{\\text{arg min}} \\sum L(y_i, F_{m-1}(x_i) + \\gamma h_m(x_i))$$\n",
    "\n",
    "* 모형 update\n",
    "\n",
    "$$F_m(x) = F_{m-1}(x) + \\gamma_m h_m(x)$$\n",
    "\n",
    "실제 구동에서는 $\\gamma$를 축소해서 사용하는 경우가 많음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀분석의 경우 잔차를 그대로 활용 : $-2\\epsilon_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GBM을 발전시킨 방법. 그래디언트만이 아니라 **2차 미분**을 사용해서 성능을 개선."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테일러 급수 전개\n",
    "\n",
    "$$\\underset{h}{\\text{arg min}} l(F(x) + h(x)) \\approx \\underset{h}{\\text{arg min}} l(F(x)) + l'(F(x))h(x) + \\frac12 l'' (F(x))h(x)^2 + \\gamma T + \\frac12 \\lambda ||h||$$\n",
    "\n",
    "> 2차 테일러급수 전개항까지 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 weight $w_j$\n",
    "\n",
    "$$-\\frac{\\sum_{i\\in I_j} l'(F(x_i))}{\\sum_{i \\in I_j} l''(F(x_i)) + \\lambda}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` XGBOOST hyperparameter\n",
    "\n",
    "learning_rate : 학습률 <-> 나무의 크기. 두 승수가 비슷해야 함.\n",
    "\n",
    "gamma : 최소 손실 감소율(감소하지 않으면 쓰지 않음)\n",
    "\n",
    "max_depth : 나무의 최대 깊이(표준적으로 5정도 쓰는 것 같음)\n",
    "\n",
    "min_child_weight : 헤시안 값의 최소값(weight에서 분모가 0에 가까워지지 않도록 함)\n",
    "\n",
    "sub_sample : 서브 샘플링 비율\n",
    "\n",
    "col** : 변수에 대한 부분 선택\n",
    "\n",
    "sampling_method : 균일/그래디언트 기반\n",
    "\n",
    "lambda/alpha : weight에 대한 normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
